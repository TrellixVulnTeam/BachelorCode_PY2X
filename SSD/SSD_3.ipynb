{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch \n",
    "from src.evaluate import evaluate\n",
    "from src.utils import dboxes300_coco, Encoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "Using cache found in /home/bohumil/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "precision = 'fp32'\n",
    "ssd_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd', model_math=precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "4952"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 3
    }
   ],
   "source": [
    "import argparse\n",
    "from src.data import get_val_dataset, get_val_dataloader, get_coco_ground_truth\n",
    "\n",
    "COCO_PATH = \"/home/bohumil/FIIT/BP/BP/Zdroje_kod/coco/\"\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(args=[])\n",
    "args.data = COCO_PATH\n",
    "\n",
    "dataset = get_val_dataset(args)\n",
    "len(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "list"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 4
    }
   ],
   "source": [
    "type([500])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "split1, _ = torch.utils.data.random_split(dataset, [1000, 4952-1000])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.05s)\n",
      "creating index...\n",
      "index created!\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "args.eval_batch_size = 10\n",
    "args.num_workers = 1\n",
    "args.distributed = False\n",
    "\n",
    "dataloader = get_val_dataloader(split1, args)\n",
    "truth = get_coco_ground_truth(args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Base precision\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from src.evaluate import evaluate\n",
    "from src.utils import dboxes300_coco, Encoder\n",
    "\n",
    "dboxes = dboxes300_coco()\n",
    "encoder = Encoder(dboxes)\n",
    "inv_map = {v: k for k, v in dataset.label_map.items()}\n",
    "\n",
    "args.no_cuda = False\n",
    "args.amp = False\n",
    "args.local_rank = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-cfd41b1b5702>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mssd_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ssd_model' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'ssd_model' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "evaluate(ssd_model, dataloader, truth, encoder, inv_map, args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "torch.save(ssd_model.state_dict(), './SSD_orig_state.st')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wrapped version for quantizer\n",
    "Zmenime kostru siete na Distiller ResNet\n",
    "\n",
    "teda v src/model\n",
    "\n",
    "```python\n",
    "# from torchvision.models.resnet import resnet18, resnet34, resnet50, resnet101, resnet152\n",
    "from distiller.models.imagenet import resnet18, resnet34, resnet50, resnet101, resnet152\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    }
   ],
   "source": [
    "from src.model import SSD300 , ResNet\n",
    "\n",
    "ssd_dist = SSD300()\n",
    "ssd_dist.load_state_dict(torch.load('./SSD_orig_state.st'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Parsing batch: 99/100\r\n",
      "Predicting Ended, total time: 219.17 s\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(30710, 7)\n",
      "0/30710\n",
      "DONE (t=0.43s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=11.45s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.83s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.054\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.056\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.023\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.058\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.091\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.048\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.066\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.066\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.027\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.071\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.106\n",
      "Current AP: 0.05450\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "0.05449888307143274"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 16
    }
   ],
   "source": [
    "evaluate(ssd_dist, dataloader, truth, encoder, inv_map, args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Getting stats for quantizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from distiller.data_loggers import collect_quant_stats, QuantCalibrationStatsCollector\n",
    "import distiller\n",
    "\n",
    "#man_model = torch.load('./manual.checkpoint.pth.tar')\n",
    "torch.cuda.empty_cache()\n",
    "distiller.utils.assign_layer_fq_names(ssd_dist)\n",
    "collector = QuantCalibrationStatsCollector(ssd_dist)\n",
    "\n",
    "stats_file = './acts_quantization_stats.yaml'\n",
    "\n",
    "if not os.path.isfile(stats_file):\n",
    "    def eval_for_stats(model):\n",
    "        evaluate(model, dataloader, truth, encoder, inv_map, args)\n",
    "    collect_quant_stats(ssd_dist, eval_for_stats, save_dir='.')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from distiller.quantization import PostTrainLinearQuantizer\n",
    "\n",
    "def make_quantizer(cpu_model, config_file_path):\n",
    "    \"\"\"returns stats_before_prepare, quantizer\"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    distiller.quantization.add_post_train_quant_args(parser)\n",
    "    args = parser.parse_args(args=[])\n",
    "    \n",
    "    #this needs to be defined in config file\n",
    "    # args.qe_stats_file = os.path.expanduser(stats_file)\n",
    "    \n",
    "    #config present, ALL OTHER args are IGNORED\n",
    "    args.qe_config_file = os.path.expanduser(config_file_path)\n",
    "    \n",
    "    cp = deepcopy(cpu_model)\n",
    "    quantizer = PostTrainLinearQuantizer.from_args(cp, args)\n",
    "    \n",
    "    # Quantizer magic\n",
    "    stats_before_prepare = deepcopy(quantizer.model_activation_stats)\n",
    "    \n",
    "    # dummy input of (batch_size, height, width, depth)\n",
    "    # https://towardsdatascience.com/understanding-input-and-output-shapes-in-convolution-network-keras-f143923d56ca\n",
    "    dummy_input = (torch.zeros(1,3,300,300) )\n",
    "\n",
    "    quantizer.prepare_model(dummy_input)\n",
    "    \n",
    "    return stats_before_prepare, quantizer\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stats_file = '/home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/SSD/acts_quantization_stats.yaml'\n",
    "config_file = '/home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/SSD/ssd_coco_post_train.yaml'\n",
    "stats_before_quantization8, quantizer8 = make_quantizer(ssd_dist,config_file)\n",
    "\n",
    "config_file = '/home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/SSD/ssd_coco_post_train_4bit.yaml'\n",
    "stats_before_quantization4, quantizer4 = make_quantizer(ssd_dist,config_file)\n",
    "\n",
    "config_file = '/home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/SSD/ssd_coco_post_train_2bit.yaml'\n",
    "stats_before_quantization2, quantizer2 = make_quantizer(ssd_dist,config_file)\n",
    "\n",
    "quantizer8.model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8 bit kvantizacia\n",
    "\n",
    "\n",
    "```python\n",
    "bits_activations: 8\n",
    "bits_parameters: 8\n",
    "bits_accum: 16\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ee8a1040cbf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconfig_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/SSD/ssd_coco_post_train.yaml'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# ssd_dist = ssd_dist.cpu()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mstats_before_quantization8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantizer8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_quantizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mssd_dist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'make_quantizer' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'make_quantizer' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "stats_file = '/home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/SSD/acts_quantization_stats.yaml'\n",
    "config_file = '/home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/SSD/ssd_coco_post_train.yaml'\n",
    "# ssd_dist = ssd_dist.cpu()\n",
    "stats_before_quantization8, quantizer8 = make_quantizer(ssd_dist,config_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "SSD300(\n  (feature_extractor): ResNet(\n    (feature_extractor): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      (4): Sequential(\n        (0): DistillerBottleneck(\n          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (downsample): Sequential(\n            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (add): EltwiseAdd()\n          (relu3): ReLU(inplace=True)\n        )\n        (1): DistillerBottleneck(\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (add): EltwiseAdd()\n          (relu3): ReLU(inplace=True)\n        )\n        (2): DistillerBottleneck(\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (add): EltwiseAdd()\n          (relu3): ReLU(inplace=True)\n        )\n      )\n      (5): Sequential(\n        (0): DistillerBottleneck(\n          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (downsample): Sequential(\n            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (add): EltwiseAdd()\n          (relu3): ReLU(inplace=True)\n        )\n        (1): DistillerBottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (add): EltwiseAdd()\n          (relu3): ReLU(inplace=True)\n        )\n        (2): DistillerBottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (add): EltwiseAdd()\n          (relu3): ReLU(inplace=True)\n        )\n        (3): DistillerBottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (add): EltwiseAdd()\n          (relu3): ReLU(inplace=True)\n        )\n      )\n      (6): Sequential(\n        (0): DistillerBottleneck(\n          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (downsample): Sequential(\n            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (add): EltwiseAdd()\n          (relu3): ReLU(inplace=True)\n        )\n        (1): DistillerBottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (add): EltwiseAdd()\n          (relu3): ReLU(inplace=True)\n        )\n        (2): DistillerBottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (add): EltwiseAdd()\n          (relu3): ReLU(inplace=True)\n        )\n        (3): DistillerBottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (add): EltwiseAdd()\n          (relu3): ReLU(inplace=True)\n        )\n        (4): DistillerBottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (add): EltwiseAdd()\n          (relu3): ReLU(inplace=True)\n        )\n        (5): DistillerBottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (add): EltwiseAdd()\n          (relu3): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (additional_blocks): ModuleList(\n    (0): Sequential(\n      (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (1): Sequential(\n      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (2): Sequential(\n      (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (3): Sequential(\n      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (4): Sequential(\n      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (loc): ModuleList(\n    (0): Conv2d(1024, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  )\n  (conf): ModuleList(\n    (0): Conv2d(1024, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): Conv2d(512, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (2): Conv2d(512, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): Conv2d(256, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): Conv2d(256, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (5): Conv2d(256, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  )\n)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 11
    }
   ],
   "source": [
    "ssd_dist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "SSD300(\n  (feature_extractor): ResNet(\n    (feature_extractor): Sequential(\n      (0): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=62.817833, output_zero_point=0.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n      )\n      (1): Identity()\n      (2): Identity()\n      (3): RangeLinearFakeQuantWrapper(\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=62.817841, output_zero_point=0.000000\n        wrapped_module_float_dtype=torch.float32.\n        (wrapped_module): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      )\n      (4): Sequential(\n        (0): DistillerBottleneck(\n          (conv1): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=149.533340, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn1): Identity()\n          (relu1): Identity()\n          (conv2): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=125.693901, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          )\n          (bn2): Identity()\n          (relu2): Identity()\n          (conv3): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=59.721771, output_zero_point=-113.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn3): Identity()\n          (downsample): Sequential(\n            (0): RangeLinearQuantParamLayerWrapper(\n              weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n              output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n                inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n              scale_approx_mult_bits=None\n              preset_activation_stats=True\n                output_scale=41.401878, output_zero_point=-148.000000\n              weights_scale=PerCh, weights_zero_point=PerCh\n              (wrapped_module): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n            )\n            (1): Identity()\n          )\n          (add): RangeLinearQuantEltwiseAddWrapper(\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=78.956909, output_zero_point=0.000000\n            (wrapped_module): EltwiseAdd()\n          )\n          (relu3): Identity()\n        )\n        (1): DistillerBottleneck(\n          (conv1): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=137.301987, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn1): Identity()\n          (relu1): Identity()\n          (conv2): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=108.363411, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          )\n          (bn2): Identity()\n          (relu2): Identity()\n          (conv3): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=59.468403, output_zero_point=-141.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn3): Identity()\n          (add): RangeLinearQuantEltwiseAddWrapper(\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=66.624237, output_zero_point=0.000000\n            (wrapped_module): EltwiseAdd()\n          )\n          (relu3): Identity()\n        )\n        (2): DistillerBottleneck(\n          (conv1): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=113.602127, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn1): Identity()\n          (relu1): Identity()\n          (conv2): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=66.672981, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          )\n          (bn2): Identity()\n          (relu2): Identity()\n          (conv3): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=45.390209, output_zero_point=-139.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn3): Identity()\n          (add): RangeLinearQuantEltwiseAddWrapper(\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=66.406433, output_zero_point=0.000000\n            (wrapped_module): EltwiseAdd()\n          )\n          (relu3): Identity()\n        )\n      )\n      (5): Sequential(\n        (0): DistillerBottleneck(\n          (conv1): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=98.441780, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn1): Identity()\n          (relu1): Identity()\n          (conv2): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=112.355148, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n          )\n          (bn2): Identity()\n          (relu2): Identity()\n          (conv3): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=43.835037, output_zero_point=-113.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn3): Identity()\n          (downsample): Sequential(\n            (0): RangeLinearQuantParamLayerWrapper(\n              weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n              output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n                inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n              scale_approx_mult_bits=None\n              preset_activation_stats=True\n                output_scale=62.039913, output_zero_point=-119.000000\n              weights_scale=PerCh, weights_zero_point=PerCh\n              (wrapped_module): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n            )\n            (1): Identity()\n          )\n          (add): RangeLinearQuantEltwiseAddWrapper(\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=77.392906, output_zero_point=0.000000\n            (wrapped_module): EltwiseAdd()\n          )\n          (relu3): Identity()\n        )\n        (1): DistillerBottleneck(\n          (conv1): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=248.942337, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn1): Identity()\n          (relu1): Identity()\n          (conv2): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=143.238632, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          )\n          (bn2): Identity()\n          (relu2): Identity()\n          (conv3): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=45.973038, output_zero_point=-124.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn3): Identity()\n          (add): RangeLinearQuantEltwiseAddWrapper(\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=71.969009, output_zero_point=0.000000\n            (wrapped_module): EltwiseAdd()\n          )\n          (relu3): Identity()\n        )\n        (2): DistillerBottleneck(\n          (conv1): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=143.234436, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn1): Identity()\n          (relu1): Identity()\n          (conv2): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=161.363602, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          )\n          (bn2): Identity()\n          (relu2): Identity()\n          (conv3): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=67.168976, output_zero_point=-126.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn3): Identity()\n          (add): RangeLinearQuantEltwiseAddWrapper(\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=71.891991, output_zero_point=0.000000\n            (wrapped_module): EltwiseAdd()\n          )\n          (relu3): Identity()\n        )\n        (3): DistillerBottleneck(\n          (conv1): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=126.425201, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn1): Identity()\n          (relu1): Identity()\n          (conv2): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=147.008911, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          )\n          (bn2): Identity()\n          (relu2): Identity()\n          (conv3): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=67.543106, output_zero_point=-123.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn3): Identity()\n          (add): RangeLinearQuantEltwiseAddWrapper(\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=68.741631, output_zero_point=0.000000\n            (wrapped_module): EltwiseAdd()\n          )\n          (relu3): Identity()\n        )\n      )\n      (6): Sequential(\n        (0): DistillerBottleneck(\n          (conv1): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=91.878769, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn1): Identity()\n          (relu1): Identity()\n          (conv2): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=117.718201, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          )\n          (bn2): Identity()\n          (relu2): Identity()\n          (conv3): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=53.670647, output_zero_point=-120.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn3): Identity()\n          (downsample): Sequential(\n            (0): RangeLinearQuantParamLayerWrapper(\n              weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n              output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n                inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n              scale_approx_mult_bits=None\n              preset_activation_stats=True\n                output_scale=62.275352, output_zero_point=-124.000000\n              weights_scale=PerCh, weights_zero_point=PerCh\n              (wrapped_module): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n            )\n            (1): Identity()\n          )\n          (add): RangeLinearQuantEltwiseAddWrapper(\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=77.231461, output_zero_point=0.000000\n            (wrapped_module): EltwiseAdd()\n          )\n          (relu3): Identity()\n        )\n        (1): DistillerBottleneck(\n          (conv1): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=90.137367, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn1): Identity()\n          (relu1): Identity()\n          (conv2): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=143.468491, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          )\n          (bn2): Identity()\n          (relu2): Identity()\n          (conv3): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=46.783901, output_zero_point=-117.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn3): Identity()\n          (add): RangeLinearQuantEltwiseAddWrapper(\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=58.953854, output_zero_point=0.000000\n            (wrapped_module): EltwiseAdd()\n          )\n          (relu3): Identity()\n        )\n        (2): DistillerBottleneck(\n          (conv1): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=126.308945, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn1): Identity()\n          (relu1): Identity()\n          (conv2): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=150.265656, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          )\n          (bn2): Identity()\n          (relu2): Identity()\n          (conv3): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=70.370071, output_zero_point=-143.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn3): Identity()\n          (add): RangeLinearQuantEltwiseAddWrapper(\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=74.701660, output_zero_point=0.000000\n            (wrapped_module): EltwiseAdd()\n          )\n          (relu3): Identity()\n        )\n        (3): DistillerBottleneck(\n          (conv1): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=102.588921, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn1): Identity()\n          (relu1): Identity()\n          (conv2): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=146.022522, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          )\n          (bn2): Identity()\n          (relu2): Identity()\n          (conv3): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=67.394264, output_zero_point=-134.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn3): Identity()\n          (add): RangeLinearQuantEltwiseAddWrapper(\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=73.465233, output_zero_point=0.000000\n            (wrapped_module): EltwiseAdd()\n          )\n          (relu3): Identity()\n        )\n        (4): DistillerBottleneck(\n          (conv1): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=108.485451, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn1): Identity()\n          (relu1): Identity()\n          (conv2): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=126.745628, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          )\n          (bn2): Identity()\n          (relu2): Identity()\n          (conv3): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=53.597046, output_zero_point=-136.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn3): Identity()\n          (add): RangeLinearQuantEltwiseAddWrapper(\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=69.577591, output_zero_point=0.000000\n            (wrapped_module): EltwiseAdd()\n          )\n          (relu3): Identity()\n        )\n        (5): DistillerBottleneck(\n          (conv1): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=114.549652, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn1): Identity()\n          (relu1): Identity()\n          (conv2): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=109.157654, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          )\n          (bn2): Identity()\n          (relu2): Identity()\n          (conv3): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=29.155176, output_zero_point=-148.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn3): Identity()\n          (add): RangeLinearQuantEltwiseAddWrapper(\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=49.965393, output_zero_point=0.000000\n            (wrapped_module): EltwiseAdd()\n          )\n          (relu3): Identity()\n        )\n      )\n    )\n  )\n  (additional_blocks): ModuleList(\n    (0): Sequential(\n      (0): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=40.913795, output_zero_point=0.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (1): Identity()\n      (2): Identity()\n      (3): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=35.249031, output_zero_point=0.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      )\n      (4): Identity()\n      (5): Identity()\n    )\n    (1): Sequential(\n      (0): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=47.183434, output_zero_point=0.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (1): Identity()\n      (2): Identity()\n      (3): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=35.142284, output_zero_point=0.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      )\n      (4): Identity()\n      (5): Identity()\n    )\n    (2): Sequential(\n      (0): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=50.702705, output_zero_point=0.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (1): Identity()\n      (2): Identity()\n      (3): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=30.837177, output_zero_point=0.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      )\n      (4): Identity()\n      (5): Identity()\n    )\n    (3): Sequential(\n      (0): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=88.518799, output_zero_point=0.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (1): Identity()\n      (2): Identity()\n      (3): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=49.273998, output_zero_point=0.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n      )\n      (4): Identity()\n      (5): Identity()\n    )\n    (4): Sequential(\n      (0): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=114.918625, output_zero_point=0.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (1): Identity()\n      (2): Identity()\n      (3): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=48.900272, output_zero_point=0.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n      )\n      (4): Identity()\n      (5): Identity()\n    )\n  )\n  (loc): ModuleList(\n    (0): RangeLinearQuantParamLayerWrapper(\n      weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n      output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n      accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n      scale_approx_mult_bits=None\n      preset_activation_stats=True\n        output_scale=19.480635, output_zero_point=-185.000000\n      weights_scale=PerCh, weights_zero_point=PerCh\n      (wrapped_module): Conv2d(1024, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (1): RangeLinearQuantParamLayerWrapper(\n      weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n      output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n      accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n      scale_approx_mult_bits=None\n      preset_activation_stats=True\n        output_scale=41.018524, output_zero_point=-126.000000\n      weights_scale=PerCh, weights_zero_point=PerCh\n      (wrapped_module): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (2): RangeLinearQuantParamLayerWrapper(\n      weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n      output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n      accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n      scale_approx_mult_bits=None\n      preset_activation_stats=True\n        output_scale=37.526051, output_zero_point=-148.000000\n      weights_scale=PerCh, weights_zero_point=PerCh\n      (wrapped_module): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (3): RangeLinearQuantParamLayerWrapper(\n      weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n      output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n      accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n      scale_approx_mult_bits=None\n      preset_activation_stats=True\n        output_scale=48.932514, output_zero_point=-132.000000\n      weights_scale=PerCh, weights_zero_point=PerCh\n      (wrapped_module): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (4): RangeLinearQuantParamLayerWrapper(\n      weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n      output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n      accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n      scale_approx_mult_bits=None\n      preset_activation_stats=True\n        output_scale=57.299503, output_zero_point=-137.000000\n      weights_scale=PerCh, weights_zero_point=PerCh\n      (wrapped_module): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (5): RangeLinearQuantParamLayerWrapper(\n      weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n      output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n      accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n      scale_approx_mult_bits=None\n      preset_activation_stats=True\n        output_scale=92.224251, output_zero_point=-139.000000\n      weights_scale=PerCh, weights_zero_point=PerCh\n      (wrapped_module): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (conf): ModuleList(\n    (0): RangeLinearQuantParamLayerWrapper(\n      weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n      output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n      accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n      scale_approx_mult_bits=None\n      preset_activation_stats=True\n        output_scale=15.546651, output_zero_point=-64.000000\n      weights_scale=PerCh, weights_zero_point=PerCh\n      (wrapped_module): Conv2d(1024, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (1): RangeLinearQuantParamLayerWrapper(\n      weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n      output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n      accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n      scale_approx_mult_bits=None\n      preset_activation_stats=True\n        output_scale=14.494864, output_zero_point=-62.000000\n      weights_scale=PerCh, weights_zero_point=PerCh\n      (wrapped_module): Conv2d(512, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (2): RangeLinearQuantParamLayerWrapper(\n      weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n      output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n      accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n      scale_approx_mult_bits=None\n      preset_activation_stats=True\n        output_scale=14.327878, output_zero_point=-59.000000\n      weights_scale=PerCh, weights_zero_point=PerCh\n      (wrapped_module): Conv2d(512, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (3): RangeLinearQuantParamLayerWrapper(\n      weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n      output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n      accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n      scale_approx_mult_bits=None\n      preset_activation_stats=True\n        output_scale=15.148595, output_zero_point=-62.000000\n      weights_scale=PerCh, weights_zero_point=PerCh\n      (wrapped_module): Conv2d(256, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (4): RangeLinearQuantParamLayerWrapper(\n      weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n      output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n      accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n      scale_approx_mult_bits=None\n      preset_activation_stats=True\n        output_scale=17.973083, output_zero_point=-59.000000\n      weights_scale=PerCh, weights_zero_point=PerCh\n      (wrapped_module): Conv2d(256, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (5): RangeLinearQuantParamLayerWrapper(\n      weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n      output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n      accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n      scale_approx_mult_bits=None\n      preset_activation_stats=True\n        output_scale=24.892042, output_zero_point=-45.000000\n      weights_scale=PerCh, weights_zero_point=PerCh\n      (wrapped_module): Conv2d(256, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 12
    }
   ],
   "source": [
    "quantizer8.model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Toto je problem\n",
    "in src/utils.py/ decode_single\n",
    "\n",
    "```python\n",
    "# mask = score > 0.05 povodne\n",
    "mask = score > 0.02\n",
    "\n",
    "bboxes, score = bboxes_in[mask, :], score[mask]\n",
    "if score.size(0) == 0: continue\n",
    "\n",
    "score_sorted, score_idx_sorted = score.sort(dim=0)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Parsing batch: 4/5\r\n",
      "Predicting Ended, total time: 38.32 s\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(4581, 7)\n",
      "0/4581\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=7.49s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.35s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "Current AP: 0.00000\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "2.928457184486667e-07"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 13
    }
   ],
   "source": [
    "# model = deepcopy(quantizer8.model).to('cpu')\n",
    "# model = model.cpu()\n",
    "args.no_cuda = False\n",
    "\n",
    "evaluate(quantizer8.model, dataloader, truth, encoder, inv_map, args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ked zmenime masku\n",
    "in src/utils.py/ decode_single\n",
    "\n",
    "```python\n",
    "mask = score > 0.05 #povodne\n",
    "# mask = score > 0.02\n",
    "\n",
    "bboxes, score = bboxes_in[mask, :], score[mask]\n",
    "if score.size(0) == 0: continue\n",
    "\n",
    "score_sorted, score_idx_sorted = score.sort(dim=0)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Parsing batch: 4/5\r\n",
      "Predicting Ended, total time: 46.09 s\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(0,)\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-04ecead51efb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_cuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquantizer8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/SSD/src/evaluate.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, coco, cocoGt, encoder, inv_map, args)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicting Ended, total time: {:.2f} s\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mcocoDt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcocoGt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadRes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCOCOeval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcocoGt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcocoDt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miouType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bbox'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/SSD/src/coco.py\u001b[0m in \u001b[0;36mloadRes\u001b[0;34m(self, resFile)\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0manns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresFile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0manns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadNumpyAnnotations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0manns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresFile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/SSD/src/coco.py\u001b[0m in \u001b[0;36mloadNumpyAnnotations\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m         \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0mann\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ],
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error"
    }
   ],
   "source": [
    "args.no_cuda = False\n",
    "\n",
    "evaluate(quantizer8.model, dataloader, truth, encoder, inv_map, args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Spominany error **nie je  chyba implementacie evaluate.** Error vyplyva z masky, lebo nic cez seba nepusti. Neviem aka je architektura siete a ci tam prave kvoli kvantizacii nedava male cisla, ktore treba previest na velke, aby presli maskou (pretoze neexistuje aby pri 8bit nevedel detekovat nic)\n",
    "\n",
    "\n",
    "Preto ani nebudem robit pokusy pre menej bit, toto musim opravit."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4 bit kvantizacia\n",
    "```python\n",
    "bits_activations: 4\n",
    "bits_parameters: 4\n",
    "bits_accum: 8\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3176a30ef2f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconfig_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/SSD/ssd_coco_post_train_4bit.yaml'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstats_before_quantization4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantizer4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_quantizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mssd_dist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquantizer4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-75da97d0c7e5>\u001b[0m in \u001b[0;36mmake_quantizer\u001b[0;34m(cpu_model, config_file_path)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mdummy_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mquantizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstats_before_prepare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/distiller/distiller/quantization/range_linear.py\u001b[0m in \u001b[0;36mprepare_model\u001b[0;34m(self, dummy_input)\u001b[0m\n\u001b[1;32m   1967\u001b[0m             raise UnsatisfiedRequirements('PostTrainLinearQuantizer requires dummy '\n\u001b[1;32m   1968\u001b[0m                                           'input in order to perform certain optimizations')\n\u001b[0;32m-> 1969\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPostTrainLinearQuantizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m         \u001b[0msave_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsglogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogdir\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsglogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'logdir'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/distiller/distiller/quantization/quantizer.py\u001b[0m in \u001b[0;36mprepare_model\u001b[0;34m(self, dummy_input)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdummy_input\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0msummary_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistiller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSummaryGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjacency_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjacency_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdedicated_modules_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mmodel_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistiller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/distiller/distiller/summary_graph.py\u001b[0m in \u001b[0;36madjacency_map\u001b[0;34m(self, dedicated_modules_only)\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0;31m# Find the immediate preceding and succeeding modules. Depth of 1 gets us the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0;31m# input and output tensors, depth of 2 gets the actual modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m             entry.predecessors = [op_meta(n) for n in self.predecessors(op, 2, denorm_names=False)\n\u001b[0m\u001b[1;32m    541\u001b[0m                                   if self._dedicated_module_check(n, dedicated_modules_only)]\n\u001b[1;32m    542\u001b[0m             entry.successors = [op_meta(n) for n in self.successors(op, 2, denorm_names=False)\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/distiller/distiller/summary_graph.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0;31m# input and output tensors, depth of 2 gets the actual modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m             entry.predecessors = [op_meta(n) for n in self.predecessors(op, 2, denorm_names=False)\n\u001b[0;32m--> 541\u001b[0;31m                                   if self._dedicated_module_check(n, dedicated_modules_only)]\n\u001b[0m\u001b[1;32m    542\u001b[0m             entry.successors = [op_meta(n) for n in self.successors(op, 2, denorm_names=False)\n\u001b[1;32m    543\u001b[0m                                 if self._dedicated_module_check(n, dedicated_modules_only)]\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/distiller/distiller/summary_graph.py\u001b[0m in \u001b[0;36mop_meta\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mop_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mOpSimpleMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistiller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdenormalize_module_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dedicated_module_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdedicated_modules_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/distiller/distiller/utils.py\u001b[0m in \u001b[0;36mdenormalize_module_name\u001b[0;34m(parallel_model, normalized_name)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0mwhich\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0;34m\"artifacts\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mDataParallel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \"\"\"\n\u001b[0;32m--> 149\u001b[0;31m     fully_qualified_name = [mod_name for mod_name, _ in parallel_model.named_modules() if\n\u001b[0m\u001b[1;32m    150\u001b[0m                             normalize_module_name(mod_name) == normalized_name]\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfully_qualified_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/distiller/distiller/utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0mwhich\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0;34m\"artifacts\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mDataParallel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \"\"\"\n\u001b[0;32m--> 149\u001b[0;31m     fully_qualified_name = [mod_name for mod_name, _ in parallel_model.named_modules() if\n\u001b[0m\u001b[1;32m    150\u001b[0m                             normalize_module_name(mod_name) == normalized_name]\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfully_qualified_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/dist_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_modules\u001b[0;34m(self, memo, prefix)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m                 \u001b[0msubmodule_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/dist_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_modules\u001b[0;34m(self, memo, prefix)\u001b[0m\n\u001b[1;32m   1043\u001b[0m                 \u001b[0msubmodule_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/snap/pycharm-professional/183/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_trace_dispatch_regular.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    468\u001b[0m                     \u001b[0mpy_db\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_skips_cache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_cache_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m                 )\n\u001b[0;32m--> 470\u001b[0;31m             ).trace_dispatch(frame, event, arg)\n\u001b[0m\u001b[1;32m    471\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m                 \u001b[0mcache_skips\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframe_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/snap/pycharm-professional/183/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    493\u001b[0m                 \u001b[0mis_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m                 \u001b[0mis_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m                 \u001b[0mis_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'return'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m                 \u001b[0mis_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ],
   "source": [
    "config_file = '/home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/SSD/ssd_coco_post_train_4bit.yaml'\n",
    "stats_before_quantization4, quantizer4 = make_quantizer(ssd_dist,config_file)\n",
    "\n",
    "evaluate(quantizer4.model, dataloader, truth, encoder, inv_map, args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2 bit kvantizacia\n",
    "```python\n",
    "bits_activations: 2\n",
    "bits_parameters: 2\n",
    "bits_accum: 2\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config_file = '/home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/SSD/ssd_coco_post_train_2bit.yaml'\n",
    "stats_before_quantization2, quantizer2 = make_quantizer(ssd_dist,config_file)\n",
    "evaluate(quantizer2.model, dataloader, truth, encoder, inv_map, args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}