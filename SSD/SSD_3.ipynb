{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch \n",
    "from src.evaluate import evaluate\n",
    "from src.utils import dboxes300_coco, Encoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "Using cache found in /home/bohumil/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "precision = 'fp32'\n",
    "ssd_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd', model_math=precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "4952"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "import argparse\n",
    "from src.data import get_val_dataset, get_val_dataloader, get_coco_ground_truth\n",
    "\n",
    "COCO_PATH = \"/home/bohumil/FIIT/BP/BP/Zdroje_kod/coco/\"\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(args=[])\n",
    "args.data = COCO_PATH\n",
    "\n",
    "dataset = get_val_dataset(args)\n",
    "len(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "list"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 3
    }
   ],
   "source": [
    "type([500])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "split1, _ = torch.utils.data.random_split(dataset, [50, 4952-50])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.78s)\n",
      "creating index...\n",
      "index created!\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "args.eval_batch_size = 10\n",
    "args.num_workers = 1\n",
    "args.distributed = False\n",
    "\n",
    "dataloader = get_val_dataloader(split1, args)\n",
    "truth = get_coco_ground_truth(args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Base precision"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from src.evaluate import evaluate\n",
    "from src.utils import dboxes300_coco, Encoder\n",
    "\n",
    "dboxes = dboxes300_coco()\n",
    "encoder = Encoder(dboxes)\n",
    "inv_map = {v: k for k, v in dataset.label_map.items()}\n",
    "\n",
    "args.no_cuda = True\n",
    "args.amp = False\n",
    "args.local_rank = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Parsing batch: 24/25\r\n",
      "Predicting Ended, total time: 134.34 s\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(36524, 7)\n",
      "0/36524\n",
      "DONE (t=0.27s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=12.11s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.82s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.030\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.050\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.032\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.032\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.052\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.024\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.036\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.038\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.039\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.061\n",
      "Current AP: 0.03050\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "0.030495475224678346"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    }
   ],
   "source": [
    "from src.evaluate import evaluate\n",
    "from src.utils import dboxes300_coco, Encoder\n",
    "\n",
    "dboxes = dboxes300_coco()\n",
    "encoder = Encoder(dboxes)\n",
    "inv_map = {v: k for k, v in dataset.label_map.items()}\n",
    "\n",
    "args.no_cuda = True\n",
    "args.amp = False\n",
    "args.local_rank = 0\n",
    "\n",
    "evaluate(ssd_model, dataloader, truth, encoder, inv_map, args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wrapped version for quantizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "torch.save(ssd_model.state_dict(), './SSD_orig_state.st')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 7
    }
   ],
   "source": [
    "from src.model import SSD300 , ResNet\n",
    "\n",
    "ssd_dist = SSD300()\n",
    "ssd_dist.load_state_dict(torch.load('./SSD_orig_state.st'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Getting stats for quantizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from distiller.data_loggers import collect_quant_stats, QuantCalibrationStatsCollector\n",
    "import distiller\n",
    "\n",
    "#man_model = torch.load('./manual.checkpoint.pth.tar')\n",
    "torch.cuda.empty_cache()\n",
    "distiller.utils.assign_layer_fq_names(ssd_dist)\n",
    "collector = QuantCalibrationStatsCollector(ssd_dist)\n",
    "\n",
    "stats_file = './acts_quantization_stats.yaml'\n",
    "\n",
    "if not os.path.isfile(stats_file):\n",
    "    def eval_for_stats(model):\n",
    "        evaluate(model, dataloader, truth, encoder, inv_map, args)\n",
    "    collect_quant_stats(ssd_dist, eval_for_stats, save_dir='.')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from distiller.quantization import PostTrainLinearQuantizer\n",
    "\n",
    "def make_quantizer(cpu_model, config_file_path):\n",
    "    \"\"\"returns stats_before_prepare, quantizer\"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    distiller.quantization.add_post_train_quant_args(parser)\n",
    "    args = parser.parse_args(args=[])\n",
    "    \n",
    "    #this needs to be defined in config file\n",
    "    # args.qe_stats_file = os.path.expanduser(stats_file)\n",
    "    \n",
    "    #config present, ALL OTHER args are IGNORED\n",
    "    args.qe_config_file = os.path.expanduser(config_file_path)\n",
    "    \n",
    "    cp = deepcopy(cpu_model)\n",
    "    quantizer = PostTrainLinearQuantizer.from_args(cp, args)\n",
    "    \n",
    "    # Quantizer magic\n",
    "    stats_before_prepare = deepcopy(quantizer.model_activation_stats)\n",
    "    \n",
    "    # dummy input of (batch_size, height, width, depth)\n",
    "    # https://towardsdatascience.com/understanding-input-and-output-shapes-in-convolution-network-keras-f143923d56ca\n",
    "    dummy_input = (torch.zeros(1,3,300,300) )\n",
    "\n",
    "    quantizer.prepare_model(dummy_input)\n",
    "    \n",
    "    return stats_before_prepare, quantizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a0b01bc263fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mconfig_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/SSD/ssd_coco_post_train_2bit.yaml'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mstats_before_quantization2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantizer2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_quantizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mssd_dist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mquantizer8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-75da97d0c7e5>\u001b[0m in \u001b[0;36mmake_quantizer\u001b[0;34m(cpu_model, config_file_path)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mdummy_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mquantizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstats_before_prepare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/distiller/distiller/quantization/range_linear.py\u001b[0m in \u001b[0;36mprepare_model\u001b[0;34m(self, dummy_input)\u001b[0m\n\u001b[1;32m   1967\u001b[0m             raise UnsatisfiedRequirements('PostTrainLinearQuantizer requires dummy '\n\u001b[1;32m   1968\u001b[0m                                           'input in order to perform certain optimizations')\n\u001b[0;32m-> 1969\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPostTrainLinearQuantizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m         \u001b[0msave_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsglogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogdir\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsglogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'logdir'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/distiller/distiller/quantization/quantizer.py\u001b[0m in \u001b[0;36mprepare_model\u001b[0;34m(self, dummy_input)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mmodel_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistiller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pre_prepare_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pre_process_container\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/distiller/distiller/quantization/range_linear.py\u001b[0m in \u001b[0;36m_pre_prepare_model\u001b[0;34m(self, dummy_input)\u001b[0m\n\u001b[1;32m   1974\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_prepare_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1975\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_bidi_distiller_lstm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1976\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_bn_folding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1977\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_activation_stats_fusions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_fuse_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/distiller/distiller/quantization/range_linear.py\u001b[0m in \u001b[0;36m_apply_bn_folding\u001b[0;34m(self, dummy_input)\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m         \u001b[0;31m# After BN folding model need to re-generate the adjacency map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2011\u001b[0;31m         \u001b[0msummary_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistiller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSummaryGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2012\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjacency_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjacency_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdedicated_modules_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/distiller/distiller/summary_graph.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, dummy_input, apply_scope_name_workarounds)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mdummy_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistiller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tensors_recursively_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdummy_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdummy_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trace_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_clone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;31m# As of PyTorch 1.3.0, ONNX trace optimization has an issue that results in incorrect scope names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/dist_env/lib/python3.7/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mget_trace_graph\u001b[0;34m(f, args, kwargs, _force_outplace, return_inputs, _return_inputs_states)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mLegacyTracedModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/dist_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/dist_env/lib/python3.7/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;31m# for now.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0minputs_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_trace_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrace_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0minputs_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/dist_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/dist_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mtracing_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traced_module_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mtracing_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/SSD/src/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mdetection_feed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/dist_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/dist_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mtracing_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traced_module_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mtracing_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/SSD/src/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/dist_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/dist_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mtracing_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traced_module_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mtracing_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/dist_env/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/dist_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/dist_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mtracing_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traced_module_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mtracing_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/dist_env/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/dist_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/dist_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mtracing_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traced_module_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mtracing_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/distiller/distiller/models/imagenet/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/dist_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/dist_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mtracing_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traced_module_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mtracing_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/dist_env/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/dist_env/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 1.96 GiB total capacity; 1016.89 MiB already allocated; 1.75 MiB free; 109.11 MiB cached)"
     ],
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 1.96 GiB total capacity; 1016.89 MiB already allocated; 1.75 MiB free; 109.11 MiB cached)",
     "output_type": "error"
    }
   ],
   "source": [
    "stats_file = '/home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/SSD/acts_quantization_stats.yaml'\n",
    "config_file = '/home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/SSD/ssd_coco_post_train.yaml'\n",
    "stats_before_quantization8, quantizer8 = make_quantizer(ssd_dist,config_file)\n",
    "\n",
    "config_file = '/home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/SSD/ssd_coco_post_train_4bit.yaml'\n",
    "stats_before_quantization4, quantizer4 = make_quantizer(ssd_dist,config_file)\n",
    "\n",
    "config_file = '/home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/SSD/ssd_coco_post_train_2bit.yaml'\n",
    "stats_before_quantization2, quantizer2 = make_quantizer(ssd_dist,config_file)\n",
    "\n",
    "quantizer8.model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8 bit kvantizacia\n",
    "\n",
    "```python\n",
    "bits_activations: 8\n",
    "bits_parameters: 8\n",
    "bits_accum: 16\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "stats_file = '/home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/SSD/acts_quantization_stats.yaml'\n",
    "config_file = '/home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/SSD/ssd_coco_post_train.yaml'\n",
    "# ssd_dist = ssd_dist.cpu()\n",
    "stats_before_quantization8, quantizer8 = make_quantizer(ssd_dist,config_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "SSD300(\n  (feature_extractor): ResNet(\n    (feature_extractor): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      (4): Sequential(\n        (0): DistillerBottleneck(\n          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (downsample): Sequential(\n            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (add): EltwiseAdd()\n          (relu3): ReLU(inplace=True)\n        )\n        (1): DistillerBottleneck(\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (add): EltwiseAdd()\n          (relu3): ReLU(inplace=True)\n        )\n        (2): DistillerBottleneck(\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (add): EltwiseAdd()\n          (relu3): ReLU(inplace=True)\n        )\n      )\n      (5): Sequential(\n        (0): DistillerBottleneck(\n          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (downsample): Sequential(\n            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (add): EltwiseAdd()\n          (relu3): ReLU(inplace=True)\n        )\n        (1): DistillerBottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (add): EltwiseAdd()\n          (relu3): ReLU(inplace=True)\n        )\n        (2): DistillerBottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (add): EltwiseAdd()\n          (relu3): ReLU(inplace=True)\n        )\n        (3): DistillerBottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (add): EltwiseAdd()\n          (relu3): ReLU(inplace=True)\n        )\n      )\n      (6): Sequential(\n        (0): DistillerBottleneck(\n          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (downsample): Sequential(\n            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n          (add): EltwiseAdd()\n          (relu3): ReLU(inplace=True)\n        )\n        (1): DistillerBottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (add): EltwiseAdd()\n          (relu3): ReLU(inplace=True)\n        )\n        (2): DistillerBottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (add): EltwiseAdd()\n          (relu3): ReLU(inplace=True)\n        )\n        (3): DistillerBottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (add): EltwiseAdd()\n          (relu3): ReLU(inplace=True)\n        )\n        (4): DistillerBottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (add): EltwiseAdd()\n          (relu3): ReLU(inplace=True)\n        )\n        (5): DistillerBottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (add): EltwiseAdd()\n          (relu3): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (additional_blocks): ModuleList(\n    (0): Sequential(\n      (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (1): Sequential(\n      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (2): Sequential(\n      (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (3): Sequential(\n      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n    (4): Sequential(\n      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (loc): ModuleList(\n    (0): Conv2d(1024, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  )\n  (conf): ModuleList(\n    (0): Conv2d(1024, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): Conv2d(512, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (2): Conv2d(512, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): Conv2d(256, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): Conv2d(256, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (5): Conv2d(256, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  )\n)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 12
    }
   ],
   "source": [
    "ssd_dist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "SSD300(\n  (feature_extractor): ResNet(\n    (feature_extractor): Sequential(\n      (0): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=62.817833, output_zero_point=0.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n      )\n      (1): Identity()\n      (2): Identity()\n      (3): RangeLinearFakeQuantWrapper(\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=62.817841, output_zero_point=0.000000\n        wrapped_module_float_dtype=torch.float32.\n        (wrapped_module): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      )\n      (4): Sequential(\n        (0): DistillerBottleneck(\n          (conv1): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=149.533340, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn1): Identity()\n          (relu1): Identity()\n          (conv2): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=125.693901, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          )\n          (bn2): Identity()\n          (relu2): Identity()\n          (conv3): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=59.721771, output_zero_point=-113.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn3): Identity()\n          (downsample): Sequential(\n            (0): RangeLinearQuantParamLayerWrapper(\n              weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n              output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n                inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n              scale_approx_mult_bits=None\n              preset_activation_stats=True\n                output_scale=41.401878, output_zero_point=-148.000000\n              weights_scale=PerCh, weights_zero_point=PerCh\n              (wrapped_module): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n            )\n            (1): Identity()\n          )\n          (add): RangeLinearQuantEltwiseAddWrapper(\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=78.956909, output_zero_point=0.000000\n            (wrapped_module): EltwiseAdd()\n          )\n          (relu3): Identity()\n        )\n        (1): DistillerBottleneck(\n          (conv1): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=137.301987, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn1): Identity()\n          (relu1): Identity()\n          (conv2): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=108.363411, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          )\n          (bn2): Identity()\n          (relu2): Identity()\n          (conv3): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=59.468403, output_zero_point=-141.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn3): Identity()\n          (add): RangeLinearQuantEltwiseAddWrapper(\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=66.624237, output_zero_point=0.000000\n            (wrapped_module): EltwiseAdd()\n          )\n          (relu3): Identity()\n        )\n        (2): DistillerBottleneck(\n          (conv1): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=113.602127, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn1): Identity()\n          (relu1): Identity()\n          (conv2): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=66.672981, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          )\n          (bn2): Identity()\n          (relu2): Identity()\n          (conv3): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=45.390209, output_zero_point=-139.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn3): Identity()\n          (add): RangeLinearQuantEltwiseAddWrapper(\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=66.406433, output_zero_point=0.000000\n            (wrapped_module): EltwiseAdd()\n          )\n          (relu3): Identity()\n        )\n      )\n      (5): Sequential(\n        (0): DistillerBottleneck(\n          (conv1): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=98.441780, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn1): Identity()\n          (relu1): Identity()\n          (conv2): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=112.355148, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n          )\n          (bn2): Identity()\n          (relu2): Identity()\n          (conv3): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=43.835037, output_zero_point=-113.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn3): Identity()\n          (downsample): Sequential(\n            (0): RangeLinearQuantParamLayerWrapper(\n              weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n              output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n                inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n              scale_approx_mult_bits=None\n              preset_activation_stats=True\n                output_scale=62.039913, output_zero_point=-119.000000\n              weights_scale=PerCh, weights_zero_point=PerCh\n              (wrapped_module): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n            )\n            (1): Identity()\n          )\n          (add): RangeLinearQuantEltwiseAddWrapper(\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=77.392906, output_zero_point=0.000000\n            (wrapped_module): EltwiseAdd()\n          )\n          (relu3): Identity()\n        )\n        (1): DistillerBottleneck(\n          (conv1): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=248.942337, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn1): Identity()\n          (relu1): Identity()\n          (conv2): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=143.238632, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          )\n          (bn2): Identity()\n          (relu2): Identity()\n          (conv3): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=45.973038, output_zero_point=-124.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn3): Identity()\n          (add): RangeLinearQuantEltwiseAddWrapper(\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=71.969009, output_zero_point=0.000000\n            (wrapped_module): EltwiseAdd()\n          )\n          (relu3): Identity()\n        )\n        (2): DistillerBottleneck(\n          (conv1): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=143.234436, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn1): Identity()\n          (relu1): Identity()\n          (conv2): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=161.363602, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          )\n          (bn2): Identity()\n          (relu2): Identity()\n          (conv3): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=67.168976, output_zero_point=-126.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn3): Identity()\n          (add): RangeLinearQuantEltwiseAddWrapper(\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=71.891991, output_zero_point=0.000000\n            (wrapped_module): EltwiseAdd()\n          )\n          (relu3): Identity()\n        )\n        (3): DistillerBottleneck(\n          (conv1): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=126.425201, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn1): Identity()\n          (relu1): Identity()\n          (conv2): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=147.008911, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          )\n          (bn2): Identity()\n          (relu2): Identity()\n          (conv3): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=67.543106, output_zero_point=-123.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn3): Identity()\n          (add): RangeLinearQuantEltwiseAddWrapper(\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=68.741631, output_zero_point=0.000000\n            (wrapped_module): EltwiseAdd()\n          )\n          (relu3): Identity()\n        )\n      )\n      (6): Sequential(\n        (0): DistillerBottleneck(\n          (conv1): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=91.878769, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn1): Identity()\n          (relu1): Identity()\n          (conv2): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=117.718201, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          )\n          (bn2): Identity()\n          (relu2): Identity()\n          (conv3): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=53.670647, output_zero_point=-120.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn3): Identity()\n          (downsample): Sequential(\n            (0): RangeLinearQuantParamLayerWrapper(\n              weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n              output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n                inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n              scale_approx_mult_bits=None\n              preset_activation_stats=True\n                output_scale=62.275352, output_zero_point=-124.000000\n              weights_scale=PerCh, weights_zero_point=PerCh\n              (wrapped_module): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n            )\n            (1): Identity()\n          )\n          (add): RangeLinearQuantEltwiseAddWrapper(\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=77.231461, output_zero_point=0.000000\n            (wrapped_module): EltwiseAdd()\n          )\n          (relu3): Identity()\n        )\n        (1): DistillerBottleneck(\n          (conv1): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=90.137367, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn1): Identity()\n          (relu1): Identity()\n          (conv2): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=143.468491, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          )\n          (bn2): Identity()\n          (relu2): Identity()\n          (conv3): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=46.783901, output_zero_point=-117.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn3): Identity()\n          (add): RangeLinearQuantEltwiseAddWrapper(\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=58.953854, output_zero_point=0.000000\n            (wrapped_module): EltwiseAdd()\n          )\n          (relu3): Identity()\n        )\n        (2): DistillerBottleneck(\n          (conv1): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=126.308945, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn1): Identity()\n          (relu1): Identity()\n          (conv2): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=150.265656, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          )\n          (bn2): Identity()\n          (relu2): Identity()\n          (conv3): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=70.370071, output_zero_point=-143.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn3): Identity()\n          (add): RangeLinearQuantEltwiseAddWrapper(\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=74.701660, output_zero_point=0.000000\n            (wrapped_module): EltwiseAdd()\n          )\n          (relu3): Identity()\n        )\n        (3): DistillerBottleneck(\n          (conv1): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=102.588921, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn1): Identity()\n          (relu1): Identity()\n          (conv2): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=146.022522, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          )\n          (bn2): Identity()\n          (relu2): Identity()\n          (conv3): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=67.394264, output_zero_point=-134.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn3): Identity()\n          (add): RangeLinearQuantEltwiseAddWrapper(\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=73.465233, output_zero_point=0.000000\n            (wrapped_module): EltwiseAdd()\n          )\n          (relu3): Identity()\n        )\n        (4): DistillerBottleneck(\n          (conv1): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=108.485451, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn1): Identity()\n          (relu1): Identity()\n          (conv2): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=126.745628, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          )\n          (bn2): Identity()\n          (relu2): Identity()\n          (conv3): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=53.597046, output_zero_point=-136.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn3): Identity()\n          (add): RangeLinearQuantEltwiseAddWrapper(\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=69.577591, output_zero_point=0.000000\n            (wrapped_module): EltwiseAdd()\n          )\n          (relu3): Identity()\n        )\n        (5): DistillerBottleneck(\n          (conv1): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=114.549652, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn1): Identity()\n          (relu1): Identity()\n          (conv2): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=109.157654, output_zero_point=0.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          )\n          (bn2): Identity()\n          (relu2): Identity()\n          (conv3): RangeLinearQuantParamLayerWrapper(\n            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n            accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=29.155176, output_zero_point=-148.000000\n            weights_scale=PerCh, weights_zero_point=PerCh\n            (wrapped_module): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (bn3): Identity()\n          (add): RangeLinearQuantEltwiseAddWrapper(\n            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n            accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n            scale_approx_mult_bits=None\n            preset_activation_stats=True\n              output_scale=49.965393, output_zero_point=0.000000\n            (wrapped_module): EltwiseAdd()\n          )\n          (relu3): Identity()\n        )\n      )\n    )\n  )\n  (additional_blocks): ModuleList(\n    (0): Sequential(\n      (0): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=40.913795, output_zero_point=0.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (1): Identity()\n      (2): Identity()\n      (3): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=35.249031, output_zero_point=0.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      )\n      (4): Identity()\n      (5): Identity()\n    )\n    (1): Sequential(\n      (0): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=47.183434, output_zero_point=0.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (1): Identity()\n      (2): Identity()\n      (3): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=35.142284, output_zero_point=0.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      )\n      (4): Identity()\n      (5): Identity()\n    )\n    (2): Sequential(\n      (0): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=50.702705, output_zero_point=0.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (1): Identity()\n      (2): Identity()\n      (3): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=30.837177, output_zero_point=0.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      )\n      (4): Identity()\n      (5): Identity()\n    )\n    (3): Sequential(\n      (0): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=88.518799, output_zero_point=0.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (1): Identity()\n      (2): Identity()\n      (3): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=49.273998, output_zero_point=0.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n      )\n      (4): Identity()\n      (5): Identity()\n    )\n    (4): Sequential(\n      (0): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=114.918625, output_zero_point=0.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (1): Identity()\n      (2): Identity()\n      (3): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=48.900272, output_zero_point=0.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n      )\n      (4): Identity()\n      (5): Identity()\n    )\n  )\n  (loc): ModuleList(\n    (0): RangeLinearQuantParamLayerWrapper(\n      weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n      output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n      accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n      scale_approx_mult_bits=None\n      preset_activation_stats=True\n        output_scale=19.480635, output_zero_point=-185.000000\n      weights_scale=PerCh, weights_zero_point=PerCh\n      (wrapped_module): Conv2d(1024, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (1): RangeLinearQuantParamLayerWrapper(\n      weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n      output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n      accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n      scale_approx_mult_bits=None\n      preset_activation_stats=True\n        output_scale=41.018524, output_zero_point=-126.000000\n      weights_scale=PerCh, weights_zero_point=PerCh\n      (wrapped_module): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (2): RangeLinearQuantParamLayerWrapper(\n      weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n      output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n      accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n      scale_approx_mult_bits=None\n      preset_activation_stats=True\n        output_scale=37.526051, output_zero_point=-148.000000\n      weights_scale=PerCh, weights_zero_point=PerCh\n      (wrapped_module): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (3): RangeLinearQuantParamLayerWrapper(\n      weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n      output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n      accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n      scale_approx_mult_bits=None\n      preset_activation_stats=True\n        output_scale=48.932514, output_zero_point=-132.000000\n      weights_scale=PerCh, weights_zero_point=PerCh\n      (wrapped_module): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (4): RangeLinearQuantParamLayerWrapper(\n      weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n      output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n      accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n      scale_approx_mult_bits=None\n      preset_activation_stats=True\n        output_scale=57.299503, output_zero_point=-137.000000\n      weights_scale=PerCh, weights_zero_point=PerCh\n      (wrapped_module): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (5): RangeLinearQuantParamLayerWrapper(\n      weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n      output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n      accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n      scale_approx_mult_bits=None\n      preset_activation_stats=True\n        output_scale=92.224251, output_zero_point=-139.000000\n      weights_scale=PerCh, weights_zero_point=PerCh\n      (wrapped_module): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (conf): ModuleList(\n    (0): RangeLinearQuantParamLayerWrapper(\n      weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n      output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n      accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n      scale_approx_mult_bits=None\n      preset_activation_stats=True\n        output_scale=15.546651, output_zero_point=-64.000000\n      weights_scale=PerCh, weights_zero_point=PerCh\n      (wrapped_module): Conv2d(1024, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (1): RangeLinearQuantParamLayerWrapper(\n      weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n      output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n      accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n      scale_approx_mult_bits=None\n      preset_activation_stats=True\n        output_scale=14.494864, output_zero_point=-62.000000\n      weights_scale=PerCh, weights_zero_point=PerCh\n      (wrapped_module): Conv2d(512, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (2): RangeLinearQuantParamLayerWrapper(\n      weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n      output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n      accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n      scale_approx_mult_bits=None\n      preset_activation_stats=True\n        output_scale=14.327878, output_zero_point=-59.000000\n      weights_scale=PerCh, weights_zero_point=PerCh\n      (wrapped_module): Conv2d(512, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (3): RangeLinearQuantParamLayerWrapper(\n      weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n      output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n      accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n      scale_approx_mult_bits=None\n      preset_activation_stats=True\n        output_scale=15.148595, output_zero_point=-62.000000\n      weights_scale=PerCh, weights_zero_point=PerCh\n      (wrapped_module): Conv2d(256, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (4): RangeLinearQuantParamLayerWrapper(\n      weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n      output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n      accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n      scale_approx_mult_bits=None\n      preset_activation_stats=True\n        output_scale=17.973083, output_zero_point=-59.000000\n      weights_scale=PerCh, weights_zero_point=PerCh\n      (wrapped_module): Conv2d(256, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (5): RangeLinearQuantParamLayerWrapper(\n      weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n      output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n      accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n      scale_approx_mult_bits=None\n      preset_activation_stats=True\n        output_scale=24.892042, output_zero_point=-45.000000\n      weights_scale=PerCh, weights_zero_point=PerCh\n      (wrapped_module): Conv2d(256, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 13
    }
   ],
   "source": [
    "quantizer8.model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Parsing batch: 4/5\r\n",
      "Predicting Ended, total time: 38.41 s\n",
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(4662, 7)\n",
      "0/4662\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=7.71s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.62s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "Current AP: 0.00000\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "3.8690418212645517e-07"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 15
    }
   ],
   "source": [
    "# model = deepcopy(quantizer8.model).to('cpu')\n",
    "# model = model.cpu()\n",
    "args.no_cuda = False\n",
    "\n",
    "evaluate(quantizer8.model, dataloader, truth, encoder, inv_map, args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4 bit kvantizacia\n",
    "```python\n",
    "bits_activations: 4\n",
    "bits_parameters: 4\n",
    "bits_accum: 8\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3176a30ef2f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconfig_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/SSD/ssd_coco_post_train_4bit.yaml'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstats_before_quantization4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantizer4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_quantizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mssd_dist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquantizer4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-75da97d0c7e5>\u001b[0m in \u001b[0;36mmake_quantizer\u001b[0;34m(cpu_model, config_file_path)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mdummy_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mquantizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstats_before_prepare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/distiller/distiller/quantization/range_linear.py\u001b[0m in \u001b[0;36mprepare_model\u001b[0;34m(self, dummy_input)\u001b[0m\n\u001b[1;32m   1967\u001b[0m             raise UnsatisfiedRequirements('PostTrainLinearQuantizer requires dummy '\n\u001b[1;32m   1968\u001b[0m                                           'input in order to perform certain optimizations')\n\u001b[0;32m-> 1969\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPostTrainLinearQuantizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m         \u001b[0msave_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsglogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogdir\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsglogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'logdir'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/distiller/distiller/quantization/quantizer.py\u001b[0m in \u001b[0;36mprepare_model\u001b[0;34m(self, dummy_input)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdummy_input\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0msummary_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistiller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSummaryGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjacency_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjacency_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdedicated_modules_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mmodel_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistiller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/distiller/distiller/summary_graph.py\u001b[0m in \u001b[0;36madjacency_map\u001b[0;34m(self, dedicated_modules_only)\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0;31m# Find the immediate preceding and succeeding modules. Depth of 1 gets us the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0;31m# input and output tensors, depth of 2 gets the actual modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m             entry.predecessors = [op_meta(n) for n in self.predecessors(op, 2, denorm_names=False)\n\u001b[0m\u001b[1;32m    541\u001b[0m                                   if self._dedicated_module_check(n, dedicated_modules_only)]\n\u001b[1;32m    542\u001b[0m             entry.successors = [op_meta(n) for n in self.successors(op, 2, denorm_names=False)\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/distiller/distiller/summary_graph.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0;31m# input and output tensors, depth of 2 gets the actual modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m             entry.predecessors = [op_meta(n) for n in self.predecessors(op, 2, denorm_names=False)\n\u001b[0;32m--> 541\u001b[0;31m                                   if self._dedicated_module_check(n, dedicated_modules_only)]\n\u001b[0m\u001b[1;32m    542\u001b[0m             entry.successors = [op_meta(n) for n in self.successors(op, 2, denorm_names=False)\n\u001b[1;32m    543\u001b[0m                                 if self._dedicated_module_check(n, dedicated_modules_only)]\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/distiller/distiller/summary_graph.py\u001b[0m in \u001b[0;36mop_meta\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mop_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mOpSimpleMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistiller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdenormalize_module_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dedicated_module_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdedicated_modules_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/distiller/distiller/utils.py\u001b[0m in \u001b[0;36mdenormalize_module_name\u001b[0;34m(parallel_model, normalized_name)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0mwhich\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0;34m\"artifacts\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mDataParallel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \"\"\"\n\u001b[0;32m--> 149\u001b[0;31m     fully_qualified_name = [mod_name for mod_name, _ in parallel_model.named_modules() if\n\u001b[0m\u001b[1;32m    150\u001b[0m                             normalize_module_name(mod_name) == normalized_name]\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfully_qualified_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/distiller/distiller/utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0mwhich\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0;34m\"artifacts\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mDataParallel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \"\"\"\n\u001b[0;32m--> 149\u001b[0;31m     fully_qualified_name = [mod_name for mod_name, _ in parallel_model.named_modules() if\n\u001b[0m\u001b[1;32m    150\u001b[0m                             normalize_module_name(mod_name) == normalized_name]\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfully_qualified_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/dist_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_modules\u001b[0;34m(self, memo, prefix)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m                 \u001b[0msubmodule_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FIIT/BP/BP/Zdroje_kod/dist_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_modules\u001b[0;34m(self, memo, prefix)\u001b[0m\n\u001b[1;32m   1043\u001b[0m                 \u001b[0msubmodule_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodule_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/snap/pycharm-professional/183/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_trace_dispatch_regular.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    468\u001b[0m                     \u001b[0mpy_db\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_skips_cache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_cache_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m                 )\n\u001b[0;32m--> 470\u001b[0;31m             ).trace_dispatch(frame, event, arg)\n\u001b[0m\u001b[1;32m    471\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m                 \u001b[0mcache_skips\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframe_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/snap/pycharm-professional/183/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    493\u001b[0m                 \u001b[0mis_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m                 \u001b[0mis_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m                 \u001b[0mis_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'return'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m                 \u001b[0mis_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ],
   "source": [
    "config_file = '/home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/SSD/ssd_coco_post_train_4bit.yaml'\n",
    "stats_before_quantization4, quantizer4 = make_quantizer(ssd_dist,config_file)\n",
    "\n",
    "evaluate(quantizer4.model, dataloader, truth, encoder, inv_map, args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2 bit kvantizacia\n",
    "```python\n",
    "bits_activations: 2\n",
    "bits_parameters: 2\n",
    "bits_accum: 2\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config_file = '/home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/SSD/ssd_coco_post_train_2bit.yaml'\n",
    "stats_before_quantization2, quantizer2 = make_quantizer(ssd_dist,config_file)\n",
    "evaluate(quantizer2.model, dataloader, truth, encoder, inv_map, args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}