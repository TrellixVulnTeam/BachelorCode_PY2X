{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ResNet kvantizácia\n",
    "\n",
    "Podľa: https://nervanasystems.github.io/distiller/prepare_model_quant.html\n",
    "\n",
    "1. Replace direct tensor operations with modules\n",
    "\n",
    "* Replace re-used modules with dedicated instances\n",
    "\n",
    "* Replace torch.nn.functional calls with equivalent modules\n",
    "\n",
    "* Special cases - replace modules that aren't quantize-able with quantize-able variants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "1.3.1\n",
      "0.4.2\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import distiller\n",
    "from distiller.models import create_model\n",
    "\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "DataParallel(\n  (module): ResNet(\n    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): DistillerBasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (add): EltwiseAdd()\n        (relu2): ReLU(inplace=True)\n      )\n      (1): DistillerBasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (add): EltwiseAdd()\n        (relu2): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): DistillerBasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (add): EltwiseAdd()\n        (relu2): ReLU(inplace=True)\n      )\n      (1): DistillerBasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (add): EltwiseAdd()\n        (relu2): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): DistillerBasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (add): EltwiseAdd()\n        (relu2): ReLU(inplace=True)\n      )\n      (1): DistillerBasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (add): EltwiseAdd()\n        (relu2): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): DistillerBasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (add): EltwiseAdd()\n        (relu2): ReLU(inplace=True)\n      )\n      (1): DistillerBasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (add): EltwiseAdd()\n        (relu2): ReLU(inplace=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n    (fc): Linear(in_features=512, out_features=1000, bias=True)\n  )\n)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "model = create_model(pretrained=True,dataset='imagenet',arch='resnet18') \n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Načítanie datasetu pre cpu a gpu (cuda)\n",
    "Používame distiller funkcionalitu v distiller.apputils.load_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = \"/home/bohumil/FIIT/BP/BP/Zdroje_kod/imagenet\"\n",
    "val_images = DATASET_PATH + \"/val/images\"\n",
    "\n",
    "\n",
    "# z <distiller_root>/jupyter/post_train_quant_convert_pytorch.ipynb\n",
    "distiller.set_seed(0)\n",
    "\n",
    "subset_size = 1.0\n",
    "val_split = 0.8\n",
    "\n",
    "batch_size_gpu = 32\n",
    "workers_gpu = 4\n",
    "train_loader_gpu, val_loader_gpu , test_loader_gpu, _ = distiller.apputils.load_data('imagenet', DATASET_PATH, batch_size=batch_size_gpu, workers=workers_gpu, \n",
    "                             validation_split=val_split, fixed_subset=False, sequential=False, \n",
    "                             test_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# z <distiller_root>/jupyter/post_train_quant_convert_pytorch.ipynb\n",
    "# for CPU vs GPU speed comparison\n",
    "distiller.set_seed(0)\n",
    "\n",
    "batch_size_cpu = 32\n",
    "num_workers_cpu = 2\n",
    "train_loader_cpu, val_loader_cpu, test_loader_cpu, _ = distiller.apputils.load_data(\n",
    "    'imagenet', DATASET_PATH, batch_size_cpu, num_workers_cpu,\n",
    "    validation_split=val_split, fixed_subset=True, test_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# z <distiller_root>/jupyter/post_train_quant_convert_pytorch.ipynb\n",
    "import torchnet as tnt\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def eval_model(data_loader, model, device='cpu', print_freq=10):\n",
    "    # print('Evaluation model ', model.arch)\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "    \n",
    "    loss = tnt.meter.AverageValueMeter()\n",
    "    classerr = tnt.meter.ClassErrorMeter(accuracy=True, topk=(1, 5))\n",
    "\n",
    "    total_samples = len(data_loader.sampler)\n",
    "    batch_size = data_loader.batch_size\n",
    "    total_steps = math.ceil(total_samples / batch_size)\n",
    "    print('{0} samples ({1} per mini-batch)'.format(total_samples, batch_size))\n",
    "\n",
    "    # Switch to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    for step, (inputs, target) in enumerate(data_loader):\n",
    "        with torch.no_grad():\n",
    "            inputs, target = inputs.to(device), target.to(device)\n",
    "            # compute output from model\n",
    "            output = model(inputs)\n",
    "\n",
    "            # compute loss and measure accuracy\n",
    "            loss.add(criterion(output, target).item())\n",
    "            classerr.add(output.data, target)\n",
    "            \n",
    "            if (step + 1) % print_freq == 0:\n",
    "                print('[{:3d}/{:3d}] Top1: {:.3f}  Top5: {:.3f}  Loss: {:.3f}'.format(\n",
    "                      step + 1, total_steps, classerr.value(1), classerr.value(5), loss.mean), flush=True)\n",
    "    print('----------')\n",
    "    print('Overall ==> Top1: {:.3f}  Top5: {:.3f}  Loss: {:.3f} PPL: {:.3f}'.format(\n",
    "        classerr.value(1), classerr.value(5), loss.mean, np.exp(loss.mean)), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "5831 samples (64 per mini-batch)\n",
      "[ 10/ 92] Top1: 0.000  Top5: 0.781  Loss: 15.164\n",
      "[ 20/ 92] Top1: 0.391  Top5: 1.406  Loss: 15.054\n",
      "[ 30/ 92] Top1: 0.313  Top5: 1.458  Loss: 15.067\n",
      "[ 40/ 92] Top1: 0.352  Top5: 1.289  Loss: 15.125\n",
      "[ 50/ 92] Top1: 0.406  Top5: 1.313  Loss: 15.032\n",
      "[ 60/ 92] Top1: 0.443  Top5: 1.380  Loss: 15.034\n",
      "[ 70/ 92] Top1: 0.402  Top5: 1.272  Loss: 15.025\n",
      "[ 80/ 92] Top1: 0.371  Top5: 1.250  Loss: 15.028\n",
      "[ 90/ 92] Top1: 0.330  Top5: 1.285  Loss: 15.039\n",
      "----------\n",
      "Overall ==> Top1: 0.326  Top5: 1.286  Loss: 15.063 PPL: 3480915.028\n",
      "CPU times: user 1min 14s, sys: 1.02 s, total: 1min 15s\n",
      "Wall time: 1min 15s\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    %time eval_model(val_loader_gpu,model,'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cpu_model = distiller.make_non_parallel_copy(model).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%time eval_model(val_loader_cpu, cpu_model, 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Quantization\n",
    "\n",
    "## 0. Collect activation statistics\n",
    "\n",
    "Resnet *as is* contains parallel modules, we need to use non-parallel model copy for stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "3888 samples (32 per mini-batch)\n",
      "[ 10/122] Top1: 1.250  Top5: 7.188  Loss: 15.298\n",
      "[ 20/122] Top1: 0.938  Top5: 6.719  Loss: 15.130\n",
      "[ 30/122] Top1: 0.938  Top5: 6.042  Loss: 15.375\n",
      "[ 40/122] Top1: 0.859  Top5: 5.156  Loss: 15.362\n",
      "[ 50/122] Top1: 1.062  Top5: 5.188  Loss: 15.352\n",
      "[ 60/122] Top1: 1.146  Top5: 5.417  Loss: 15.259\n",
      "[ 70/122] Top1: 1.161  Top5: 5.268  Loss: 15.249\n",
      "[ 80/122] Top1: 1.211  Top5: 4.922  Loss: 15.283\n",
      "[ 90/122] Top1: 1.215  Top5: 4.861  Loss: 15.335\n",
      "[100/122] Top1: 1.281  Top5: 4.656  Loss: 15.327\n",
      "[110/122] Top1: 1.278  Top5: 4.688  Loss: 15.331\n",
      "[120/122] Top1: 1.354  Top5: 4.583  Loss: 15.333\n",
      "----------\n",
      "Overall ==> Top1: 1.337  Top5: 4.578  Loss: 15.353 PPL: 4654219.261\n",
      "3888 samples (32 per mini-batch)\n",
      "[ 10/122] Top1: 0.938  Top5: 3.438  Loss: 15.544\n",
      "[ 20/122] Top1: 1.094  Top5: 3.750  Loss: 15.603\n",
      "[ 30/122] Top1: 1.562  Top5: 4.688  Loss: 15.504\n",
      "[ 40/122] Top1: 1.484  Top5: 4.844  Loss: 15.424\n",
      "[ 50/122] Top1: 1.625  Top5: 4.937  Loss: 15.341\n",
      "[ 60/122] Top1: 1.510  Top5: 4.635  Loss: 15.416\n",
      "[ 70/122] Top1: 1.429  Top5: 4.598  Loss: 15.407\n",
      "[ 80/122] Top1: 1.328  Top5: 4.453  Loss: 15.435\n",
      "[ 90/122] Top1: 1.424  Top5: 4.514  Loss: 15.405\n",
      "[100/122] Top1: 1.375  Top5: 4.500  Loss: 15.417\n",
      "[110/122] Top1: 1.392  Top5: 4.517  Loss: 15.433\n",
      "[120/122] Top1: 1.380  Top5: 4.453  Loss: 15.426\n",
      "----------\n",
      "Overall ==> Top1: 1.363  Top5: 4.475  Loss: 15.439 PPL: 5068406.226\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# z distiller/examples/word_language_model/quantize_lstm.ipynb\n",
    "import os\n",
    "import torch\n",
    "from distiller.data_loggers import collect_quant_stats, QuantCalibrationStatsCollector\n",
    "\n",
    "#man_model = torch.load('./manual.checkpoint.pth.tar')\n",
    "distiller.utils.assign_layer_fq_names(cpu_model)\n",
    "collector = QuantCalibrationStatsCollector(cpu_model)\n",
    "\n",
    "stats_file = './acts_quantization_stats.yaml'\n",
    "\n",
    "if not os.path.isfile(stats_file):\n",
    "    def eval_for_stats(model):\n",
    "        eval_model(data_loader=train_loader_cpu,model=model)\n",
    "    collect_quant_stats(cpu_model, eval_for_stats, save_dir='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Teraz mame ziskane statistiky z train datasetu. Podla tychto statistik mozeme nastavit kvantizaciu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pokracujeme upravenim torchvision impl. na nas pripad\n",
    "\n",
    "## 1. Replace direct tensor operations with modules\n",
    "\n",
    "*   mali sme v forward_imp vyuzittie `torch.flatten`\n",
    "*   mali sme aj + v `BasicBlock`\n",
    "\n",
    "## 2. Replace re-used modules with dedicated instances\n",
    "\n",
    "*   V BasicBlock viac krat `nn.Relu`\n",
    "\n",
    "## 3. Replace `torch.nn.functional` calls with equivalent modules\n",
    " \n",
    "\n",
    "Taktiez dolezite je volanie\n",
    "\n",
    "```python\n",
    "...\n",
    "\n",
    "_resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress,\n",
    "                   **kwargs)\n",
    "                   \n",
    "...\n",
    "\n",
    "def _resnet(arch, block, layers, pretrained, progress, **kwargs):\n",
    "    model = ResNet(block, layers, **kwargs)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Evaluate quantized model\n",
    "\n",
    "### we should also save model for re-use ?\n",
    "Skusim len spustit kvantizaciu Resnet18 podla quantization_jupyters/resnet18_imagenet_post_train.yaml\n",
    "Implementacia Resnet v Distiller uz pouziva vsade modules, teda nie je nutne vytvaranie noveho korektneho modelu.\n",
    "**Preto mozem rovno pustit kvantizaciu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from distiller.quantization import PostTrainLinearQuantizer\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Predpripravy, ziskanie statistik modelu pred kvantizaciou, kvantizovanie modelu"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# deepcopy(cpu_model)\n",
    "def make_quantizer(cpu_model, config_file_path):\n",
    "    \"\"\"returns stats_before_prepare, quantizer\"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    distiller.quantization.add_post_train_quant_args(parser)\n",
    "    args = parser.parse_args(args=[])\n",
    "    \n",
    "    #this needs to be defined in config file\n",
    "    # args.qe_stats_file = os.path.expanduser(stats_file)\n",
    "    \n",
    "    #config present, ALL OTHER args are IGNORED\n",
    "    args.qe_config_file = os.path.expanduser(config_file_path)\n",
    "    \n",
    "    cp = deepcopy(cpu_model)\n",
    "    quantizer = PostTrainLinearQuantizer.from_args(cp, args)\n",
    "    \n",
    "    # Quantizer magic\n",
    "    stats_before_prepare = deepcopy(quantizer.model_activation_stats)\n",
    "    \n",
    "    # dummy input of (batch_size, height, width, depth)\n",
    "    # https://towardsdatascience.com/understanding-input-and-output-shapes-in-convolution-network-keras-f143923d56ca\n",
    "    dummy_input = (torch.zeros(64,3,7,7) )\n",
    "\n",
    "    quantizer.prepare_model(dummy_input)\n",
    "    \n",
    "    return stats_before_prepare, quantizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Porovnajme statistiky oboch modelov\n",
    "Porovnanie statistiky pred a po kvantizacii ResNet18"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=1)\n",
    "print('Stats BEFORE prepare_model:')\n",
    "pp.pprint(stats_before_prepare['rnn.cells.0.eltwiseadd_gate']['output'])\n",
    "\n",
    "print('\\nStats AFTER to prepare_model:')\n",
    "pp.pprint(quantizer.model_activation_stats['rnn.cells.0.eltwiseadd_gate']['output'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): RangeLinearQuantParamLayerWrapper(\n    weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n    output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n    accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n      inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n    scale_approx_mult_bits=None\n    preset_activation_stats=True\n      output_scale=75.812683, output_zero_point=0.000000\n    weights_scale=PerCh, weights_zero_point=PerCh\n    (wrapped_module): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n  )\n  (bn1): Identity()\n  (relu): Identity()\n  (maxpool): RangeLinearFakeQuantWrapper(\n    output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n    accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n      inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n    scale_approx_mult_bits=None\n    preset_activation_stats=True\n      output_scale=75.812813, output_zero_point=0.000000\n    wrapped_module_float_dtype=torch.float32.\n    (wrapped_module): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  )\n  (layer1): Sequential(\n    (0): DistillerBasicBlock(\n      (conv1): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=140.982574, output_zero_point=0.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n      (bn1): Identity()\n      (relu1): Identity()\n      (conv2): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=45.577793, output_zero_point=-144.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n      (bn2): Identity()\n      (add): RangeLinearQuantEltwiseAddWrapper(\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=67.524529, output_zero_point=0.000000\n        (wrapped_module): EltwiseAdd()\n      )\n      (relu2): Identity()\n    )\n    (1): DistillerBasicBlock(\n      (conv1): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=122.528343, output_zero_point=0.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n      (bn1): Identity()\n      (relu1): Identity()\n      (conv2): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=33.118633, output_zero_point=-145.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n      (bn2): Identity()\n      (add): RangeLinearQuantEltwiseAddWrapper(\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=50.530930, output_zero_point=0.000000\n        (wrapped_module): EltwiseAdd()\n      )\n      (relu2): Identity()\n    )\n  )\n  (layer2): Sequential(\n    (0): DistillerBasicBlock(\n      (conv1): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=127.051323, output_zero_point=0.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      )\n      (bn1): Identity()\n      (relu1): Identity()\n      (conv2): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=45.672005, output_zero_point=-108.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n      (bn2): Identity()\n      (downsample): Sequential(\n        (0): RangeLinearQuantParamLayerWrapper(\n          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n          scale_approx_mult_bits=None\n          preset_activation_stats=True\n            output_scale=58.660648, output_zero_point=-135.000000\n          weights_scale=PerCh, weights_zero_point=PerCh\n          (wrapped_module): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n        )\n        (1): Identity()\n      )\n      (add): RangeLinearQuantEltwiseAddWrapper(\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=74.580521, output_zero_point=0.000000\n        (wrapped_module): EltwiseAdd()\n      )\n      (relu2): Identity()\n    )\n    (1): DistillerBasicBlock(\n      (conv1): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=123.477356, output_zero_point=0.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n      (bn1): Identity()\n      (relu1): Identity()\n      (conv2): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=42.772846, output_zero_point=-134.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n      (bn2): Identity()\n      (add): RangeLinearQuantEltwiseAddWrapper(\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=58.498421, output_zero_point=0.000000\n        (wrapped_module): EltwiseAdd()\n      )\n      (relu2): Identity()\n    )\n  )\n  (layer3): Sequential(\n    (0): DistillerBasicBlock(\n      (conv1): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=115.831535, output_zero_point=0.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      )\n      (bn1): Identity()\n      (relu1): Identity()\n      (conv2): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=48.693264, output_zero_point=-109.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n      (bn2): Identity()\n      (downsample): Sequential(\n        (0): RangeLinearQuantParamLayerWrapper(\n          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n          scale_approx_mult_bits=None\n          preset_activation_stats=True\n            output_scale=137.437408, output_zero_point=-164.000000\n          weights_scale=PerCh, weights_zero_point=PerCh\n          (wrapped_module): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n        )\n        (1): Identity()\n      )\n      (add): RangeLinearQuantEltwiseAddWrapper(\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=85.895576, output_zero_point=0.000000\n        (wrapped_module): EltwiseAdd()\n      )\n      (relu2): Identity()\n    )\n    (1): DistillerBasicBlock(\n      (conv1): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=141.669754, output_zero_point=0.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n      (bn1): Identity()\n      (relu1): Identity()\n      (conv2): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=48.271133, output_zero_point=-152.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n      (bn2): Identity()\n      (add): RangeLinearQuantEltwiseAddWrapper(\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=81.290405, output_zero_point=0.000000\n        (wrapped_module): EltwiseAdd()\n      )\n      (relu2): Identity()\n    )\n  )\n  (layer4): Sequential(\n    (0): DistillerBasicBlock(\n      (conv1): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=174.063278, output_zero_point=0.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      )\n      (bn1): Identity()\n      (relu1): Identity()\n      (conv2): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=45.433628, output_zero_point=-126.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n      (bn2): Identity()\n      (downsample): Sequential(\n        (0): RangeLinearQuantParamLayerWrapper(\n          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n          scale_approx_mult_bits=None\n          preset_activation_stats=True\n            output_scale=69.322586, output_zero_point=-131.000000\n          weights_scale=PerCh, weights_zero_point=PerCh\n          (wrapped_module): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n        )\n        (1): Identity()\n      )\n      (add): RangeLinearQuantEltwiseAddWrapper(\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=73.552803, output_zero_point=0.000000\n        (wrapped_module): EltwiseAdd()\n      )\n      (relu2): Identity()\n    )\n    (1): DistillerBasicBlock(\n      (conv1): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=169.384125, output_zero_point=0.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n      (bn1): Identity()\n      (relu1): Identity()\n      (conv2): RangeLinearQuantParamLayerWrapper(\n        weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n        accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=9.786680, output_zero_point=-91.000000\n        weights_scale=PerCh, weights_zero_point=PerCh\n        (wrapped_module): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n      (bn2): Identity()\n      (add): RangeLinearQuantEltwiseAddWrapper(\n        output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)\n        accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n          inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n        scale_approx_mult_bits=None\n        preset_activation_stats=True\n          output_scale=14.108895, output_zero_point=0.000000\n        (wrapped_module): EltwiseAdd()\n      )\n      (relu2): Identity()\n    )\n  )\n  (avgpool): RangeLinearFakeQuantWrapper(\n    output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n    accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n      inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n    scale_approx_mult_bits=None\n    preset_activation_stats=True\n      output_scale=41.918602, output_zero_point=0.000000\n    wrapped_module_float_dtype=torch.float32.\n    (wrapped_module): AdaptiveAvgPool2d(output_size=(1, 1))\n  )\n  (fc): RangeLinearQuantParamLayerWrapper(\n    weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=True)\n    output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n    accum_quant_settings=(num_bits=16 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)\n      inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None\n    scale_approx_mult_bits=None\n    preset_activation_stats=True\n      output_scale=10.991887, output_zero_point=-75.000000\n    weights_scale=PerCh, weights_zero_point=PerCh\n    (wrapped_module): Linear(in_features=512, out_features=1000, bias=True)\n  )\n)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 15
    }
   ],
   "source": [
    "stats_file = '/home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/acts_quantization_stats.yaml'\n",
    "config_file = '/home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/resnet18_imagenet_post_train.yaml'\n",
    "stats_before_quantization, quantizer = make_quantizer(cpu_model,config_file)\n",
    "quantizer.model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Base - full precision cuda model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "15551 samples (32 per mini-batch)\n",
      "[ 60/486] Top1: 0.365  Top5: 1.042  Loss: 15.124\n",
      "[120/486] Top1: 0.339  Top5: 1.068  Loss: 15.157\n",
      "[180/486] Top1: 0.330  Top5: 1.146  Loss: 15.099\n",
      "[240/486] Top1: 0.313  Top5: 1.172  Loss: 15.091\n",
      "[300/486] Top1: 0.292  Top5: 1.208  Loss: 15.050\n",
      "[360/486] Top1: 0.339  Top5: 1.337  Loss: 15.032\n",
      "[420/486] Top1: 0.335  Top5: 1.317  Loss: 15.013\n",
      "[480/486] Top1: 0.306  Top5: 1.289  Loss: 15.012\n",
      "----------\n",
      "Overall ==> Top1: 0.315  Top5: 1.286  Loss: 15.019 PPL: 3331843.514\n",
      "CPU times: user 3min 44s, sys: 2.65 s, total: 3min 47s\n",
      "Wall time: 3min 39s\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "%time eval_model(val_loader_gpu, model, 'cuda', print_freq=60)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "10000 samples (64 per mini-batch)\n",
      "[ 10/157] Top1: 0.000  Top5: 0.000  Loss: 10.656\n",
      "[ 20/157] Top1: 0.156  Top5: 0.313  Loss: 10.582\n",
      "[ 30/157] Top1: 0.156  Top5: 0.417  Loss: 10.580\n",
      "[ 40/157] Top1: 0.156  Top5: 0.508  Loss: 10.512\n",
      "[ 50/157] Top1: 0.125  Top5: 0.594  Loss: 10.518\n",
      "[ 60/157] Top1: 0.104  Top5: 0.547  Loss: 10.550\n",
      "[ 70/157] Top1: 0.112  Top5: 0.625  Loss: 10.538\n",
      "[ 80/157] Top1: 0.098  Top5: 0.645  Loss: 10.557\n",
      "[ 90/157] Top1: 0.087  Top5: 0.608  Loss: 10.570\n",
      "[100/157] Top1: 0.078  Top5: 0.625  Loss: 10.568\n",
      "[110/157] Top1: 0.099  Top5: 0.625  Loss: 10.591\n",
      "[120/157] Top1: 0.104  Top5: 0.638  Loss: 10.590\n",
      "[130/157] Top1: 0.096  Top5: 0.673  Loss: 10.589\n",
      "[140/157] Top1: 0.089  Top5: 0.636  Loss: 10.602\n",
      "[150/157] Top1: 0.094  Top5: 0.635  Loss: 10.598\n",
      "----------\n",
      "Overall ==> Top1: 0.090  Top5: 0.630  Loss: 10.611\n",
      "CPU times: user 11min 11s, sys: 1.11 s, total: 11min 12s\n",
      "Wall time: 11min 8s\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "%time eval_model(val_loader_cpu, cpu_model.to(device), device, print_freq=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8bit quantization evaluation\n",
    "Mame nastavenie:\n",
    "\n",
    "```python\n",
    "bits_activations: 8\n",
    "bits_parameters: 8\n",
    "bits_accum: 16\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "15551 samples (32 per mini-batch)\n",
      "[ 60/486] Top1: 0.000  Top5: 0.417  Loss: 7.366\n",
      "[120/486] Top1: 0.052  Top5: 0.443  Loss: 7.343\n",
      "[180/486] Top1: 0.087  Top5: 0.556  Loss: 7.341\n",
      "[240/486] Top1: 0.104  Top5: 0.560  Loss: 7.335\n",
      "[300/486] Top1: 0.104  Top5: 0.562  Loss: 7.336\n",
      "[360/486] Top1: 0.104  Top5: 0.564  Loss: 7.332\n",
      "[420/486] Top1: 0.089  Top5: 0.528  Loss: 7.331\n",
      "[480/486] Top1: 0.104  Top5: 0.553  Loss: 7.330\n",
      "----------\n",
      "Overall ==> Top1: 0.103  Top5: 0.553  Loss: 7.330 PPL: 1525.112\n",
      "CPU times: user 11min 7s, sys: 2.8 s, total: 11min 10s\n",
      "Wall time: 11min 1s\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "quantizer_gpu = deepcopy(quantizer.model).to('cuda')\n",
    "%time eval_model(val_loader_gpu, quantizer_gpu, 'cuda', print_freq=60)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "15551 samples (32 per mini-batch)\n",
      "[ 10/486] Top1: 0.000  Top5: 0.000  Loss: 7.285\n",
      "[ 20/486] Top1: 0.000  Top5: 0.000  Loss: 7.287\n",
      "[ 30/486] Top1: 0.000  Top5: 0.000  Loss: 7.297\n",
      "[ 40/486] Top1: 0.078  Top5: 0.078  Loss: 7.292\n",
      "[ 50/486] Top1: 0.062  Top5: 0.125  Loss: 7.292\n",
      "[ 60/486] Top1: 0.052  Top5: 0.104  Loss: 7.290\n",
      "[ 70/486] Top1: 0.045  Top5: 0.089  Loss: 7.298\n",
      "[ 80/486] Top1: 0.078  Top5: 0.195  Loss: 7.282\n",
      "[ 90/486] Top1: 0.069  Top5: 0.174  Loss: 7.279\n",
      "[100/486] Top1: 0.062  Top5: 0.156  Loss: 7.282\n",
      "[110/486] Top1: 0.057  Top5: 0.142  Loss: 7.279\n",
      "[120/486] Top1: 0.052  Top5: 0.156  Loss: 7.288\n",
      "[130/486] Top1: 0.072  Top5: 0.168  Loss: 7.287\n",
      "[140/486] Top1: 0.067  Top5: 0.179  Loss: 7.281\n",
      "[150/486] Top1: 0.083  Top5: 0.187  Loss: 7.280\n",
      "[160/486] Top1: 0.098  Top5: 0.215  Loss: 7.282\n",
      "[170/486] Top1: 0.110  Top5: 0.221  Loss: 7.273\n",
      "[180/486] Top1: 0.104  Top5: 0.208  Loss: 7.277\n",
      "[190/486] Top1: 0.099  Top5: 0.197  Loss: 7.282\n",
      "[200/486] Top1: 0.094  Top5: 0.187  Loss: 7.278\n",
      "[210/486] Top1: 0.104  Top5: 0.208  Loss: 7.279\n",
      "[220/486] Top1: 0.142  Top5: 0.256  Loss: 7.278\n",
      "[230/486] Top1: 0.136  Top5: 0.285  Loss: 7.275\n",
      "[240/486] Top1: 0.143  Top5: 0.313  Loss: 7.277\n",
      "[250/486] Top1: 0.138  Top5: 0.300  Loss: 7.277\n",
      "[260/486] Top1: 0.132  Top5: 0.300  Loss: 7.277\n",
      "[270/486] Top1: 0.139  Top5: 0.313  Loss: 7.276\n",
      "[280/486] Top1: 0.134  Top5: 0.313  Loss: 7.279\n",
      "[290/486] Top1: 0.140  Top5: 0.313  Loss: 7.280\n",
      "[300/486] Top1: 0.135  Top5: 0.313  Loss: 7.281\n",
      "[310/486] Top1: 0.141  Top5: 0.313  Loss: 7.281\n",
      "[320/486] Top1: 0.146  Top5: 0.313  Loss: 7.282\n",
      "[330/486] Top1: 0.142  Top5: 0.303  Loss: 7.282\n",
      "[340/486] Top1: 0.138  Top5: 0.294  Loss: 7.282\n",
      "[350/486] Top1: 0.134  Top5: 0.286  Loss: 7.281\n",
      "[360/486] Top1: 0.130  Top5: 0.278  Loss: 7.286\n",
      "[370/486] Top1: 0.135  Top5: 0.279  Loss: 7.286\n",
      "[380/486] Top1: 0.132  Top5: 0.280  Loss: 7.286\n",
      "[390/486] Top1: 0.136  Top5: 0.296  Loss: 7.284\n",
      "[400/486] Top1: 0.133  Top5: 0.297  Loss: 7.283\n",
      "[410/486] Top1: 0.137  Top5: 0.305  Loss: 7.284\n",
      "[420/486] Top1: 0.141  Top5: 0.305  Loss: 7.286\n",
      "[430/486] Top1: 0.145  Top5: 0.305  Loss: 7.285\n",
      "[440/486] Top1: 0.142  Top5: 0.298  Loss: 7.285\n",
      "[450/486] Top1: 0.139  Top5: 0.313  Loss: 7.285\n",
      "[460/486] Top1: 0.136  Top5: 0.306  Loss: 7.283\n",
      "[470/486] Top1: 0.133  Top5: 0.299  Loss: 7.282\n",
      "[480/486] Top1: 0.130  Top5: 0.293  Loss: 7.282\n",
      "----------\n",
      "Overall ==> Top1: 0.129  Top5: 0.289  Loss: 7.283 PPL: 1456.046\n",
      "CPU times: user 35min 47s, sys: 2min 52s, total: 38min 39s\n",
      "Wall time: 19min 28s\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "%time eval_model(val_loader_cpu, quantizer.model, 'cpu', print_freq=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4bit quantization\n",
    "Mame nastavenie:\n",
    "\n",
    "```python\n",
    "bits_activations: 4\n",
    "bits_parameters: 4\n",
    "bits_accum: 8\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "config_file = '/home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/resnet18_imagenet_post_train_4bit.yaml'\n",
    "stats_before_quantization_2, quantizer_4bit = make_quantizer(cpu_model,config_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "15551 samples (32 per mini-batch)\n",
      "[ 60/486] Top1: 0.156  Top5: 0.781  Loss: 7.427\n",
      "[120/486] Top1: 0.130  Top5: 0.677  Loss: 7.435\n",
      "[180/486] Top1: 0.104  Top5: 0.625  Loss: 7.425\n",
      "[240/486] Top1: 0.091  Top5: 0.651  Loss: 7.422\n",
      "[300/486] Top1: 0.094  Top5: 0.667  Loss: 7.418\n",
      "[360/486] Top1: 0.104  Top5: 0.694  Loss: 7.419\n",
      "[420/486] Top1: 0.119  Top5: 0.744  Loss: 7.425\n",
      "[480/486] Top1: 0.124  Top5: 0.729  Loss: 7.422\n",
      "----------\n",
      "Overall ==> Top1: 0.129  Top5: 0.746  Loss: 7.422 PPL: 1671.588\n",
      "CPU times: user 12min 2s, sys: 2.33 s, total: 12min 4s\n",
      "Wall time: 11min 56s\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "quantizer_gpu_4bit = deepcopy(quantizer_4bit.model).to('cuda')\n",
    "%time eval_model(val_loader_gpu, quantizer_gpu_4bit, 'cuda', print_freq=60)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Not used, yet...\n",
    "Distiller impl. of resnet is **wrapped** in modules "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import distiller.modules\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    __constants__ = ['downsample']\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        \n",
    "        # Added\n",
    "        \"\"\"  for quantization purposes \"\"\"\n",
    "        # (1)\n",
    "        self.add = distiller.modules.EltwiseAdd(inplace=True)\n",
    "        # (2)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        # (1) out += identity\n",
    "        out = self.add(out,identity)\n",
    "        # (2) out = self.relu(out)\n",
    "        out = self.relu2(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    __constants__ = ['downsample']\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        \n",
    "        # Added\n",
    "        \"\"\"  for quantization purposes \"\"\"\n",
    "        #(2)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        #(1)\n",
    "        self.add = distiller.modules.EltwiseAdd(inplace=True)\n",
    "        #(2)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        # out = self.relu(out)\n",
    "        out = self.relu2\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        # out += identity\n",
    "        out = self.add(out,identity)\n",
    "        # out = self.relu(out)\n",
    "        out = self.relu3\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        \n",
    "        # Added\n",
    "        \"\"\"  for quantization purposes \"\"\"\n",
    "        # (1)\n",
    "        self.flatten = distiller.modules.Flatten()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        # (1) x = torch.flatten(x, 1)\n",
    "        x = self.flatten(x,1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "def model_conversion(pytorch_model_):\n",
    "    model = ResNet(BasicBlock,[2, 2, 2, 2]).to(device)\n",
    "    # model = DistillerRNNModel(nlayers=nlayers, ninp=ninp, nhid=nhid, ntoken=ntoken, tie_weights=tie_weights).to(device)\n",
    "    model.eval()    \n",
    "    # model.encoder.weight = nn.Parameter(pytorch_model_.encoder.weight.clone().detach())\n",
    "    model.decoder.weight = nn.Parameter(pytorch_model_.decoder.weight.clone().detach())\n",
    "    model.decoder.bias = nn.Parameter(pytorch_model_.decoder.bias.clone().detach())\n",
    "    \n",
    "    \n",
    "    # model.rnn = LSTM.from_pytorch_impl(pytorch_model_.rnn)\n",
    "\n",
    "    return model\n",
    "\n",
    "man_model = model_conversion(model)\n",
    "torch.save(man_model, 'manual.checkpoint.pth.tar')\n",
    "man_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}