{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ResNet kvantiz√°cia\n",
    "\n",
    "## Obsah\n",
    "\n",
    "*   [Predspracovanie](#predspracovanie)\n",
    "<a href='#predspracovanie'> </a>\n",
    "*   [Statistiky na staticku kvant.](#stats)\n",
    "<a href='#stats'> </a>\n",
    "*   [Base precision](#base)\n",
    "<a href='#base'> </a>\n",
    "*   Range-Based Quantization\n",
    "    *   [8 bit kvantizacia](#8bit)\n",
    "<a href='#8bit'> </a>\n",
    "    *   [7 bit kvantizacia](#7bit)\n",
    "<a href='#8bit'> </a>\n",
    "    *   [6 bit kvantizacia](#6bit)\n",
    "<a href='#8bit'> </a>\n",
    "    *   [5 bit kvantizacia](#5bit)\n",
    "<a href='#8bit'> </a>\n",
    "    *   [4 bit kvantizacia](#4bit)\n",
    "<a href='#4bit'> </a>\n",
    "*   Loss-Aware Quantization\n",
    "    *   [4 bit kvantizacia](#4bit-loss)\n",
    "<a href='#4bit-loss'> </a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.1\n",
      "0.4.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import distiller\n",
    "from distiller.models import create_model\n",
    "\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='predspracovanie'> </a>\n",
    "\n",
    "# Predspracovanie"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model = create_model(pretrained=True,dataset='imagenet',arch='resnet18') "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "DataParallel(\n  (module): ResNet(\n    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): DistillerBasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (add): EltwiseAdd()\n        (relu2): ReLU(inplace=True)\n      )\n      (1): DistillerBasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (add): EltwiseAdd()\n        (relu2): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): DistillerBasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (add): EltwiseAdd()\n        (relu2): ReLU(inplace=True)\n      )\n      (1): DistillerBasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (add): EltwiseAdd()\n        (relu2): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): DistillerBasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (add): EltwiseAdd()\n        (relu2): ReLU(inplace=True)\n      )\n      (1): DistillerBasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (add): EltwiseAdd()\n        (relu2): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): DistillerBasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (add): EltwiseAdd()\n        (relu2): ReLU(inplace=True)\n      )\n      (1): DistillerBasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (add): EltwiseAdd()\n        (relu2): ReLU(inplace=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n    (fc): Linear(in_features=512, out_features=1000, bias=True)\n  )\n)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "preprocessing = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "batch_size = 40\n",
    "num_workers = 1\n",
    "dataset = torchvision.datasets.ImageFolder('/home/bohumil/FIIT/BP/BP/Zdroje_kod/imagenet/val'\n",
    "                                           ,preprocessing)\n",
    "\n",
    "small, big = torch.utils.data.random_split(dataset,[7000, len(dataset)-7000])\n",
    " \n",
    "dataloader = torch.utils.data.DataLoader(small,batch_size=batch_size,\n",
    "                                         num_workers=num_workers,shuffle=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from resnet_output import resnet_output\n",
    "\n",
    "def target_labels(dataset,target):\n",
    "    list = target.tolist()\n",
    "    for i in range(len(list)):\n",
    "        list[i] = dataset.classes[list[i]]\n",
    "        list[i] = resnet_output[list[i]]\n",
    "    return torch.LongTensor(list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# z <distiller_root>/jupyter/post_train_quant_convert_pytorch.ipynb\n",
    "import torchnet as tnt\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def eval_model(data_loader, model, device='cpu', print_freq=10):\n",
    "    # print('Evaluation model ', model.arch)\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "    \n",
    "    loss = tnt.meter.AverageValueMeter()\n",
    "    classerr = tnt.meter.ClassErrorMeter(accuracy=True, topk=(1, 5))\n",
    "    # apmeter = tnt.meter.APMeter()\n",
    "\n",
    "    total_samples = len(data_loader.sampler)\n",
    "    batch_size = data_loader.batch_size\n",
    "    total_steps = math.ceil(total_samples / batch_size)\n",
    "    print('{0} samples ({1} per mini-batch)'.format(total_samples, batch_size))\n",
    "\n",
    "    # Switch to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    for step, (inputs, target) in enumerate(data_loader):\n",
    "        with torch.no_grad():\n",
    "            inputs, target = inputs.to(device), target.to(device)\n",
    "            # compute output from model\n",
    "            output = model(inputs)\n",
    "            target = target_labels(dataset,target).to(device)\n",
    "            # compute loss and measure accuracy\n",
    "            loss.add(criterion(output, target).item())\n",
    "            classerr.add(output.data, target)\n",
    "\n",
    "            if (step + 1) % print_freq == 0:\n",
    "                print('[{:3d}/{:3d}] Top1: {:.3f}  Top5: {:.3f}  Loss: {:.3f}'.format(\n",
    "                      step + 1, total_steps, classerr.value(1), classerr.value(5), loss.mean), flush=True)\n",
    "    print('----------')\n",
    "    print('Overall ==> Top1: {:.3f}  Top5: {:.3f}  Loss: {:.3f}  PPL: {:.3f}'.format(\n",
    "        classerr.value(1), classerr.value(5), loss.mean, np.exp(loss.mean)), flush=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import logging\n",
    "def config_notebooks_logger():\n",
    "    logging.config.fileConfig('logging.conf')\n",
    "    msglogger = logging.getLogger()\n",
    "    msglogger.info('Logging configured successfully')\n",
    "    return msglogger"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging configured successfully\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import distiller\n",
    "\n",
    "msglogger = config_notebooks_logger()\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "distiller.quantization.add_post_train_quant_args(parser)\n",
    "args = parser.parse_args(args= [])\n",
    "# args.qe_config_file = '/home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/resnet18_imagenet_post_train.yaml'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='stats'> </a>\n",
    "\n",
    "# Correct way of getting statistics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cpu_model = distiller.make_non_parallel_copy(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from distiller.data_loggers import collect_quant_stats, QuantCalibrationStatsCollector, collector_context\n",
    "\n",
    "\n",
    "args.qe_calibration = 0.2\n",
    "if args.qe_calibration:\n",
    "    \n",
    "    cpu_model = distiller.make_non_parallel_copy(model).cpu()\n",
    "    \n",
    "    distiller.utils.assign_layer_fq_names(cpu_model)\n",
    "    msglogger.info(\"Generating quantization calibration stats based on {0} users\".format(args.qe_calibration))\n",
    "    collector = distiller.data_loggers.QuantCalibrationStatsCollector(cpu_model)\n",
    "    with collector_context(collector):\n",
    "        eval_model(train_loader_gpu,cpu_model,'cuda',print_freq=30)\n",
    "        # Here call your model evaluation function, making sure to execute only\n",
    "        # the portion of the dataset specified by the qe_calibration argument\n",
    "    yaml_path = './act_quantization_stats.yaml'\n",
    "    collector.save(yaml_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a href='#base'> </a>\n",
    "\n",
    "# Base precision"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000 samples (40 per mini-batch)\n",
      "[ 40/175] Top1: 76.250  Top5: 93.688  Loss: 0.885\n",
      "[ 80/175] Top1: 78.156  Top5: 93.719  Loss: 0.845\n",
      "[120/175] Top1: 78.208  Top5: 93.896  Loss: 0.838\n",
      "[160/175] Top1: 78.328  Top5: 93.922  Loss: 0.833\n",
      "----------\n",
      "Overall ==> Top1: 78.286  Top5: 93.943  Loss: 0.832  PPL: 2.298\n",
      "CPU times: user 1min 29s, sys: 841 ms, total: 1min 29s\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    %time eval_model(dataloader,model,'cuda', print_freq=40)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "args.quantize_eval = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "def eval_quantized(model, args):\n",
    "    if args.quantize_eval:\n",
    "        quantizer = distiller.quantization.PostTrainLinearQuantizer.from_args(deepcopy(model), args)\n",
    "        # dummy = distiller.get_dummy_input(model.input_shape)\n",
    "        dummy = distiller.get_dummy_input(input_shape=model.input_shape)\n",
    "        quantizer.prepare_model(dummy)\n",
    "        eval_model(dataloader, quantizer.model, 'cuda', print_freq=30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='8bit'> </a>\n",
    "\n",
    "# 8 bit quantization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading configuration from: /home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/resnet/resnet18/resnet18_imagenet_post_train.yaml\n",
      "Found component of class PostTrainLinearQuantizer: Name: post_train_quantizer ; Section: quantizers\n",
      "Loading activation stats from: /home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/resnet/acts_quantization_stats.yaml\n",
      "Preparing model for quantization using PostTrainLinearQuantizer\n",
      "Applying batch-norm folding ahead of post-training quantization\n",
      "Propagating output statistics from BN modules to folded modules\n",
      "Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n",
      "Updated stats saved to ./quant_stats_after_prepare_model.yaml\n",
      "Per-layer quantization parameters saved to ./layer_quant_params.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000 samples (40 per mini-batch)\n",
      "[ 30/175] Top1: 78.083  Top5: 93.667  Loss: 0.836\n",
      "[ 60/175] Top1: 78.042  Top5: 93.250  Loss: 0.847\n",
      "[ 90/175] Top1: 78.333  Top5: 93.333  Loss: 0.833\n",
      "[120/175] Top1: 78.125  Top5: 93.667  Loss: 0.833\n",
      "[150/175] Top1: 78.067  Top5: 93.733  Loss: 0.840\n",
      "----------\n",
      "Overall ==> Top1: 78.214  Top5: 93.886  Loss: 0.837  PPL: 2.310\n"
     ]
    }
   ],
   "source": [
    "args.qe_config_file = './resnet18/resnet18_imagenet_post_train.yaml'\n",
    "eval_quantized(model, args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='7bit'> </a>\n",
    "\n",
    "# 7 bit quantization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading configuration from: /home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/resnet/resnet18/resnet18_imagenet_post_train_7bit.yaml\n",
      "Found component of class PostTrainLinearQuantizer: Name: post_train_quantizer ; Section: quantizers\n",
      "Loading activation stats from: /home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/resnet/acts_quantization_stats.yaml\n",
      "Preparing model for quantization using PostTrainLinearQuantizer\n",
      "Applying batch-norm folding ahead of post-training quantization\n",
      "Propagating output statistics from BN modules to folded modules\n",
      "Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n",
      "Updated stats saved to ./quant_stats_after_prepare_model.yaml\n",
      "Per-layer quantization parameters saved to ./layer_quant_params.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000 samples (40 per mini-batch)\n",
      "[ 30/175] Top1: 79.000  Top5: 93.750  Loss: 0.808\n",
      "[ 60/175] Top1: 78.458  Top5: 93.667  Loss: 0.827\n",
      "[ 90/175] Top1: 77.972  Top5: 93.250  Loss: 0.846\n",
      "[120/175] Top1: 77.979  Top5: 93.458  Loss: 0.845\n",
      "[150/175] Top1: 78.483  Top5: 93.583  Loss: 0.838\n",
      "----------\n",
      "Overall ==> Top1: 78.086  Top5: 93.614  Loss: 0.845  PPL: 2.327\n"
     ]
    }
   ],
   "source": [
    "args.qe_config_file = './resnet18/resnet18_imagenet_post_train_7bit.yaml'\n",
    "eval_quantized(model, args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='6bit'> </a>\n",
    "\n",
    "# 6 bit quantization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading configuration from: /home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/resnet/resnet18/resnet18_imagenet_post_train_6bit.yaml\n",
      "Found component of class PostTrainLinearQuantizer: Name: post_train_quantizer ; Section: quantizers\n",
      "Loading activation stats from: /home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/resnet/acts_quantization_stats.yaml\n",
      "Preparing model for quantization using PostTrainLinearQuantizer\n",
      "Applying batch-norm folding ahead of post-training quantization\n",
      "Propagating output statistics from BN modules to folded modules\n",
      "Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n",
      "Updated stats saved to ./quant_stats_after_prepare_model.yaml\n",
      "Per-layer quantization parameters saved to ./layer_quant_params.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000 samples (40 per mini-batch)\n",
      "[ 30/175] Top1: 76.000  Top5: 93.000  Loss: 0.897\n",
      "[ 60/175] Top1: 76.458  Top5: 92.875  Loss: 0.903\n",
      "[ 90/175] Top1: 76.333  Top5: 93.056  Loss: 0.900\n",
      "[120/175] Top1: 76.312  Top5: 93.062  Loss: 0.907\n",
      "[150/175] Top1: 76.067  Top5: 92.967  Loss: 0.914\n",
      "----------\n",
      "Overall ==> Top1: 75.843  Top5: 92.971  Loss: 0.917  PPL: 2.502\n"
     ]
    }
   ],
   "source": [
    "args.qe_config_file = './resnet18/resnet18_imagenet_post_train_6bit.yaml'\n",
    "eval_quantized(model, args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='5bit'> </a>\n",
    "\n",
    "# 5 bit quantization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading configuration from: /home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/resnet/resnet18/resnet18_imagenet_post_train_5bit.yaml\n",
      "Found component of class PostTrainLinearQuantizer: Name: post_train_quantizer ; Section: quantizers\n",
      "Loading activation stats from: /home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/resnet/acts_quantization_stats.yaml\n",
      "Preparing model for quantization using PostTrainLinearQuantizer\n",
      "Applying batch-norm folding ahead of post-training quantization\n",
      "Propagating output statistics from BN modules to folded modules\n",
      "Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n",
      "Updated stats saved to ./quant_stats_after_prepare_model.yaml\n",
      "Per-layer quantization parameters saved to ./layer_quant_params.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000 samples (40 per mini-batch)\n",
      "[ 30/175] Top1: 64.833  Top5: 86.583  Loss: 1.375\n",
      "[ 60/175] Top1: 64.042  Top5: 86.542  Loss: 1.392\n",
      "[ 90/175] Top1: 64.778  Top5: 86.806  Loss: 1.368\n",
      "[120/175] Top1: 65.271  Top5: 87.062  Loss: 1.351\n",
      "[150/175] Top1: 65.817  Top5: 87.033  Loss: 1.338\n",
      "----------\n",
      "Overall ==> Top1: 66.000  Top5: 87.257  Loss: 1.324  PPL: 3.759\n"
     ]
    }
   ],
   "source": [
    "args.qe_config_file = './resnet18/resnet18_imagenet_post_train_5bit.yaml'\n",
    "eval_quantized(model, args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='4bit'> </a>\n",
    "\n",
    "# 4 bit quantization\n",
    "\n",
    "## Run 1\n",
    "```python\n",
    "class: PostTrainLinearQuantizer\n",
    "bits_activations: 4\n",
    "bits_parameters: 4\n",
    "bits_accum: 16\n",
    "mode: ASYMMETRIC_UNSIGNED\n",
    "per_channel_wts: True\n",
    "clip_acts: AVG\n",
    "\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading configuration from: /home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/resnet/resnet18/resnet18_imagenet_post_train_4bit.yaml\n",
      "Found component of class PostTrainLinearQuantizer: Name: post_train_quantizer ; Section: quantizers\n",
      "Loading activation stats from: /home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/resnet/acts_quantization_stats.yaml\n",
      "Preparing model for quantization using PostTrainLinearQuantizer\n",
      "Applying batch-norm folding ahead of post-training quantization\n",
      "Propagating output statistics from BN modules to folded modules\n",
      "Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n",
      "Updated stats saved to ./quant_stats_after_prepare_model.yaml\n",
      "Per-layer quantization parameters saved to ./layer_quant_params.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000 samples (40 per mini-batch)\n",
      "[ 30/175] Top1: 28.167  Top5: 51.000  Loss: 3.792\n",
      "[ 60/175] Top1: 28.000  Top5: 50.792  Loss: 3.782\n",
      "[ 90/175] Top1: 26.306  Top5: 50.389  Loss: 3.864\n",
      "[120/175] Top1: 26.812  Top5: 51.083  Loss: 3.829\n",
      "[150/175] Top1: 26.833  Top5: 50.600  Loss: 3.832\n",
      "----------\n",
      "Overall ==> Top1: 27.157  Top5: 50.829  Loss: 3.805  PPL: 44.947\n"
     ]
    }
   ],
   "source": [
    "args.qe_config_file = './resnet18/resnet18_imagenet_post_train_4bit.yaml'\n",
    "eval_quantized(model, args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Uprava parametrov\n",
    "## Run 2\n",
    "/home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/resnet18_imagenet_post_train_4bit2.yaml\n",
    "\n",
    "```python\n",
    "quantizers:\n",
    "  post_train_quantizer:\n",
    "    class: PostTrainLinearQuantizer\n",
    "    bits_activations: 4\n",
    "    bits_parameters: 4\n",
    "    bits_accum: 16\n",
    "\n",
    "    mode: ASYMMETRIC_UNSIGNED\n",
    "    \n",
    "    model_activation_stats: acts_quantization_stats.yaml\n",
    "    per_channel_wts: True\n",
    "    clip_acts: AVG\n",
    "\n",
    "    overrides:\n",
    "      fc:\n",
    "        clip_acts: NONE  # Don't clip activations in last layer before softmax\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading configuration from: /home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/resnet/resnet18/resnet18_imagenet_post_train_4bit2.yaml\n",
      "Found component of class PostTrainLinearQuantizer: Name: post_train_quantizer ; Section: quantizers\n",
      "Loading activation stats from: /home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/resnet/acts_quantization_stats.yaml\n",
      "Preparing model for quantization using PostTrainLinearQuantizer\n",
      "Applying batch-norm folding ahead of post-training quantization\n",
      "Propagating output statistics from BN modules to folded modules\n",
      "Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n",
      "Updated stats saved to ./quant_stats_after_prepare_model.yaml\n",
      "Per-layer quantization parameters saved to ./layer_quant_params.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000 samples (40 per mini-batch)\n",
      "[ 30/175] Top1: 21.500  Top5: 43.167  Loss: 4.409\n",
      "[ 60/175] Top1: 22.917  Top5: 44.375  Loss: 4.271\n",
      "[ 90/175] Top1: 22.917  Top5: 44.444  Loss: 4.244\n",
      "[120/175] Top1: 22.896  Top5: 43.937  Loss: 4.247\n",
      "[150/175] Top1: 22.717  Top5: 44.133  Loss: 4.248\n",
      "----------\n",
      "Overall ==> Top1: 22.786  Top5: 44.029  Loss: 4.263  PPL: 71.023\n"
     ]
    }
   ],
   "source": [
    "args.qe_config_file = './resnet18/resnet18_imagenet_post_train_4bit2.yaml'\n",
    "eval_quantized(model, args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "```python\n",
    " bits_accum: 32\n",
    "\n",
    " overrides:\n",
    "    # First and last layers in 8-bits\n",
    "      conv1:\n",
    "        bits_weights: 8\n",
    "        bits_activations: 8\n",
    "      fc:\n",
    "        bits_weights: 8\n",
    "        bits_activations: 8\n",
    "        clip_acts: NONE  # Don't clip activations in last layer before softmax\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading configuration from: /home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/resnet/resnet18/resnet18_imagenet_post_train_4bit3.yaml\n",
      "Found component of class PostTrainLinearQuantizer: Name: post_train_quantizer ; Section: quantizers\n",
      "Loading activation stats from: /home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/resnet/acts_quantization_stats.yaml\n",
      "Preparing model for quantization using PostTrainLinearQuantizer\n",
      "Applying batch-norm folding ahead of post-training quantization\n",
      "Propagating output statistics from BN modules to folded modules\n",
      "Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n",
      "Updated stats saved to ./quant_stats_after_prepare_model.yaml\n",
      "Per-layer quantization parameters saved to ./layer_quant_params.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000 samples (40 per mini-batch)\n",
      "[ 30/175] Top1: 35.333  Top5: 58.667  Loss: 3.260\n",
      "[ 60/175] Top1: 36.833  Top5: 60.500  Loss: 3.185\n",
      "[ 90/175] Top1: 36.833  Top5: 60.222  Loss: 3.188\n",
      "[120/175] Top1: 37.042  Top5: 60.563  Loss: 3.161\n",
      "[150/175] Top1: 37.483  Top5: 60.683  Loss: 3.151\n",
      "----------\n",
      "Overall ==> Top1: 37.571  Top5: 60.857  Loss: 3.146  PPL: 23.247\n"
     ]
    }
   ],
   "source": [
    "args.qe_config_file = './resnet18/resnet18_imagenet_post_train_4bit3.yaml'\n",
    "eval_quantized(model, args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mixed model\n",
    "\n",
    "```python\n",
    "quantizers:\n",
    "  post_train_quantizer:\n",
    "    class: PostTrainLinearQuantizer\n",
    "    bits_activations: 8\n",
    "    bits_parameters: 4\n",
    "    bits_accum: 32\n",
    "\n",
    "    mode: ASYMMETRIC_UNSIGNED\n",
    "   \n",
    "    model_activation_stats: acts_quantization_stats.yaml\n",
    "    per_channel_wts: True\n",
    "    clip_acts: AVG\n",
    "\n",
    "    overrides:\n",
    "    # First and last layers in 8-bits\n",
    "      conv1:\n",
    "        bits_weights: 8\n",
    "        bits_activations: 8\n",
    "      fc:\n",
    "        bits_weights: 8\n",
    "        bits_activations: 8\n",
    "        clip_acts: NONE  # Don't clip activations in last layer before softmax\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading configuration from: /home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/resnet/resnet18/resnet18_imagenet_post_train_4bit4.yaml\n",
      "Found component of class PostTrainLinearQuantizer: Name: post_train_quantizer ; Section: quantizers\n",
      "Loading activation stats from: /home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/resnet/acts_quantization_stats.yaml\n",
      "Preparing model for quantization using PostTrainLinearQuantizer\n",
      "Applying batch-norm folding ahead of post-training quantization\n",
      "Propagating output statistics from BN modules to folded modules\n",
      "Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n",
      "Updated stats saved to ./quant_stats_after_prepare_model.yaml\n",
      "Per-layer quantization parameters saved to ./layer_quant_params.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000 samples (40 per mini-batch)\n",
      "[ 30/175] Top1: 65.417  Top5: 86.000  Loss: 1.423\n",
      "[ 60/175] Top1: 66.708  Top5: 86.375  Loss: 1.395\n",
      "[ 90/175] Top1: 66.611  Top5: 86.972  Loss: 1.378\n",
      "[120/175] Top1: 67.021  Top5: 86.938  Loss: 1.364\n",
      "[150/175] Top1: 66.900  Top5: 86.833  Loss: 1.373\n",
      "----------\n",
      "Overall ==> Top1: 66.557  Top5: 86.729  Loss: 1.378  PPL: 3.968\n"
     ]
    }
   ],
   "source": [
    "args.qe_config_file = './resnet18/resnet18_imagenet_post_train_4bit4.yaml'\n",
    "eval_quantized(model, args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mixed model 2\n",
    "\n",
    "```python\n",
    "    overrides:\n",
    "      conv1:\n",
    "        bits_weights: 5\n",
    "        bits_activations: 8\n",
    "      fc:\n",
    "        bits_weights: 5\n",
    "        bits_activations: 8\n",
    "        clip_acts: NONE \n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading configuration from: /home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/resnet/resnet18/resnet18_imagenet_post_train_4bit5.yaml\n",
      "Found component of class PostTrainLinearQuantizer: Name: post_train_quantizer ; Section: quantizers\n",
      "Loading activation stats from: /home/bohumil/FIIT/BP/BP/Zdroje_kod/quantization_jupyters/resnet/acts_quantization_stats.yaml\n",
      "Preparing model for quantization using PostTrainLinearQuantizer\n",
      "Applying batch-norm folding ahead of post-training quantization\n",
      "Propagating output statistics from BN modules to folded modules\n",
      "Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid\n",
      "Updated stats saved to ./quant_stats_after_prepare_model.yaml\n",
      "Per-layer quantization parameters saved to ./layer_quant_params.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000 samples (40 per mini-batch)\n",
      "[ 30/175] Top1: 65.583  Top5: 85.083  Loss: 1.503\n",
      "[ 60/175] Top1: 63.583  Top5: 84.333  Loss: 1.570\n",
      "[ 90/175] Top1: 63.194  Top5: 84.417  Loss: 1.559\n",
      "[120/175] Top1: 63.542  Top5: 84.708  Loss: 1.540\n",
      "[150/175] Top1: 63.717  Top5: 84.583  Loss: 1.540\n",
      "----------\n",
      "Overall ==> Top1: 63.786  Top5: 84.871  Loss: 1.526  PPL: 4.600\n"
     ]
    }
   ],
   "source": [
    "args.qe_config_file = './resnet18/resnet18_imagenet_post_train_4bit5.yaml'\n",
    "eval_quantized(model, args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='4bit-loss'> </a>\n",
    "\n",
    "# 4 bit Loss-Aware quantization\n",
    "\n",
    "## Run 1\n",
    "\n",
    "Distiller supports Loss-Aware quantization in its sample application.\n",
    "\n",
    "[Log file](./resnet18/2020.04.23-155202/2020.04.23-155202.log)\n",
    "\n",
    "Command:\n",
    "```python\n",
    "python compress_classifier.py --eval --qe --qe-lapq -a resnet18 --pretrained ~/FIIT/BP/BP/Zdroje_kod/imagenet --lapq-eval-size 0.01 --lapq-maxiter 2 --qe-config-file ../quantization/post_train_quant/resnet18_imagenet_post_train_lapq.yaml -b 50 --lapq-init-mode LAPLACE --lapq-init-method powel --det --lapq-search-clipping\n",
    "```\n",
    "Output:\n",
    "```\n",
    "Arch: resnet18\n",
    "Test: \t top1 = 55.697 \t top5 = 79.716 \t loss = 1.887\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run 2\n",
    "\n",
    "Activations with 8 bit, weights 4 bit\n",
    "\n",
    "[Log file](./resnet18/2020.04.30-231007/2020.04.30-231007.log)\n",
    "\n",
    "Command:\n",
    "```python\n",
    "python compress_classifier.py --eval --qe --qe-lapq -a resnet18 --pretrained ~/FIIT/BP/BP/Zdroje_kod/imagenet --lapq-eval-size 0.01 --lapq-maxiter 2 --qe-config-file ../quantization/post_train_quant/resnet18_imagenet_post_train_lapq_v2.yaml -b 50 --lapq-init-mode LAPLACE --lapq-init-method powel --det --lapq-search-clipping\n",
    "```\n",
    "Output:\n",
    "```\n",
    "Arch: resnet18\n",
    "Test: \t top1 = 61.737 \t top5 = 84.773 \t loss = 1.570\n",
    "```\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}